{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.keras API자세히 배우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_data():\n",
    "    x = np.random.uniform(low=-2, high=2, size=200)\n",
    "    y = []\n",
    "    for t in x:\n",
    "        r = np.random.normal(loc=0.0, scale=(0.5+t*t/3), size=None)\n",
    "        y.append(r)\n",
    "    return x, 1.726*x-0.84+np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = make_random_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3df4xc13Uf8O+Z3SG1KydayqIjeySKEuJQNUuYtDayGqZFyLiiIVnUVopBp05rNylYp01hK8K6qyqwyMIF6RAIhaApCiIxkMCCQ/3KWooc0FZFt6gAyl5qSdO0yES2fnmsRGtLS0fiSpzdPf1j5i3fvnn3/Zh33487+/0Agnbnx3t3H3fP3HfuufeKqoKIiNxVK7sBRESUDQM5EZHjGMiJiBzHQE5E5DgGciIixw2WcdIrrrhC169fX8apiYicdfz48Z+o6trg46UE8vXr12NqaqqMUxMROUtEXgp7nKkVIiLHMZATETmOgZyIyHEM5EREjmMgJyJyXClVK0REeZqcbuLAkbP48ewc3jcyhPEdGzC2pVF2s3LDQE5EfWVyuol7Hj2FudYCAKA5O4d7Hj0FAH0bzJlaIaK+cuDI2aUg7plrLeDAkbMltSh/DORE1Fd+PDuX6vF+wEBORH3lfSNDqR7vB9YCuYgMiMi0iPy1rWMSEaU1vmMDhuoDyx4bqg9gfMeGklqUP5uDnZ8F8ByAn7d4TCKiVLwBTVatpCQiVwG4FcB/B/D7No5JRNSrsS2Nvg7cQbZSK/cD+DyARdMLRGS3iEyJyNTMzIyl0xIRUeZALiIfA/Caqh6Pep2qHlLVUVUdXbu2azldIiLqkY3UylYAO0XkFgCXAPh5EfmKqv6WhWMTEZXCpdmhmXvkqnqPql6lqusBfALAUwziROQyb3Zoc3YOiouzQyenm2U3LRTryImIAlybHWp1rRVV/RaAb9k8JhFR0VybHcoeORFRgGuzQxnIiYgCXJsdymVsiYgCXJsdykBORBQibnZolcoTGciJiFKq2uYVzJETEaVUtfJEBnIiopSqVp7IQE5ElFLVyhMZyImIUqpaeSIHO4mIYoRVqOy7Y1Nk1UqRVS0M5EREEUwVKvvu2ISnJ7aneg+QT1ULUytERBF6qVApuqqFgZyIKEIvFSpFV7UwkBMRReilQqXoqhYGciJyxuR0E1v3P4VrJ57A1v1PFbLRw/iODajXZNlj9ZpEVqgUXdXCwU4ickKp0+Il5vsOf6XKyHAdqwdrODfXyr1qhT1yInJCWdPiDxw5i9aCLnustaBd5w1uD/fG+RbemV/EwV2b8fTE9lw/bBjIicgJZU2LT3reMtdfYWqFiJzwvpEhNEOCqjeAaGMCTtgxTOetiWByurl0jjLXX2GPnIicEDWAaGPXe9Mxtl2/tuu8ALCguuwcZa6/wkBORE4Y29LAvjs2oTEyBAHQGBnCvjs2YWxLw0paw3SMo2dmsO+OTRiQ7hFO/znKXH+FqRUicoZp1x4baY2oY4xtaeCuwyci31fm9nAM5ETkPBv587hjxD0PxG8PlxemVojIeTby53GpkaotXevHQE5EzrORP486RpLnyySqGv8qy0ZHR3Vqaqrw8xKRO2yt533txBMIi3IC4IX9t2ZuZ5FE5LiqjgYfZ4+ciCrHRjmhp2rbsuWBgZxoBSpj8ak0bM6SrHJu25bMgVxErhaRoyLyfRE5LSKftdEwIsqHzd5uXmzOkvRy22uG60uPrR7srz6sjZ9mHsDdqvoBADcB+E8i8gELxyWiHJS5JkhSttMhUy+9jtnzraXvZ+dalfvwyiJzIFfVV1X12c7X/wjgOQDlD+MSUagy1wRJmtKxmQ6ZnG7igWMvdw14Vu3DKwurE4JEZD2ALQCeCXluN4DdALBu3TqbpyWiFJJMbMlDmvXEbc6SPHDkbGjVClDMh1cRrAVyEXkXgEcAfE5VfxZ8XlUPATgEtMsPbZ2XiNIZ37FhWUAFihn8i0rphAVoW7Mko4J1v1SuWAnkIlJHO4g/oKqP2jgmEeXD39ttzs5hQGRZmiGvCS5RKR1bNeNhTHcgAhRauZLnz2ijakUA/BmA51T1j7I3iYjyNralsZSHXuhMCsy7esXU+x0ZrudaRROWbxcAn7xpXWGzMvOuFLJRtbIVwL8BsF1ETnT+u8XCcYkooV7qwouuXjENYKoicTt6+TnDptYf3LUZXxzblOnnSSPva505taKq/w/GrUiJKG+9bkpcdPWKaQAzbnlYT5bNl8taldCT97XmMrZEjks7iOgpo3olLKB6ufq4dsT1astYBzypvK91f01vIlqBeu3tVWXqetJ2mH4er2de5ZmqeV9r9siJHOSvgKiJLA1Y+sX19src0aaXdph6tV7VjV+SO5I8mCpT8r7WXMaWyDGT002MP3wSrQXz3+5QfaAya2XbEsyRA+2fMxjEPUUvU2tqn81/By5jS9Qn9j5+OjSI1wSV2/DAJtPGDo2KLFNb5ho2TK0QOeYN3+JPfosKvOjYRglpmapPypipGlTmGjYM5ETktKrk+i8bqmN2rvtDtog7AwZyIseMGALGyFA95NXJ5TmFPG9l14lPTjfx1oX5rsfrNSnkzoCBnMgxe3ZuxPhDJ9FavJgnr9cEe3Zu7PmYYZNtxh8+iT2Pnca5uVbqwO59KHhruSyoouHYh0MaB46cDR23WDVYK+TnZSAnckweqYSwgbrWgi71/NPMogx+KATXcklyjKJlvRsx5cHfurCAyelm7j8vAzmRg6JSCb0EpSQDcklrs8M+FNIeo0hZpv57TDXuAAr5eRnIifpIkqAUFuijApFfkoAf95qiNnNI+oHW6xIHfuM7NuBzCdeMyQPryIlyVuSO9XG1zKblVLddv7ZrCnmYJBUYca+Jet7WtUqzbKyNssGxLQ3jYHMRVSsM5EQ5KnrH+rigZAr0R8/MLJtss2a4jnpt+aKmSWuzw9YVSXIMm9cqzeQcWxs979m5sbS1axjIiXJU9Gy/uKAUFejHtjTw9MR2vLD/Vkx/4WYc+PgHu2ZRJkk1+GdgAu21UJDgGDavVZpetq0FrUwzT1m1QuS4Imb7+XPBlw3VUR+QZaVw/qCUZjnVLLXZvbw3anXDayeeSFVNkvbnBOxUAZVVz85ATpSjvNehDg5uzs61UK8J1gzXMXu+u/67rI2Xk4gacPWnWoB2wIwazEz7c5Y9oSgrBnKiHOUdOEPrvxcVw6sGMf2Fm7ten7T3WcYsz7BrFeRPtURV51Rl2n5RuIwtUc7yDIrXTjyBsL/gLEu45r0ca9T18D9nikwCc++9MTKEpye2Z25jVZmWsWWPnChned6295q6iQqmNuqqo84b15P2zrF1/1PGn63MlQariFUrRDlJUxPda/20qdTv/IV54zHiyvzyDJJpKlOiqklslQz2CwZyohykqYnOUj/tlbwFJ6O8cb5lPEZcMDUFw5pI5vr3NB8SUeV8VdlvtCqYWiHKQZr0RNZUxtiWBg4cOdu1tK3pGHHB1DTouKCaedGrtKkgU1oqz8HMNGMaVVn6l4GcKAdpep42UhlRxwgGm5HheuguQyPD7V69F4jufvBk16bOWXPlNqt48hh7SLOAlo3FtmxhaoUoB2lyuKbXXjZUT5w3Nx1jZLjelbY5Z9gq7s23L+bVx7Y0sGioaOs1V+59oMy1FhLP9ixamhx+mXt0BjGQE+Vg2/VrEz8elu+t1wRvXZhPnDcPO4agnSsPBptFQ5tbi7osCJk+HBRIvaCVfxwAaKdpvJ54VYI4UPydlC1MrRDl4OiZmcSPh+V7Z89fwFsX4vPm/rTJyHAdqwdrmJ1rQQBjHXYUfxCKmqCTJI3gb1uts0tQ8OfZ89jpSuSYPWly+HnP2k2DgZwoo7ABr7S9NX++d3K6mWht62CO9o3zLQzVBzBcr+F8y9TvjuYPQv4PmLCAFZUvN+0SFDQ71+ppF6IwNgYe0+Twq7TcgZXUioh8VETOisjzIjJh45hELjCVDnoDh0FJemtROVb/+0052l6DeFgQ8lZEFMN7TB9MUbsERek1x2xrCdw0KxiWudphUOYeuYgMAPgTAP8SwI8AfEdEHlPV72c9NlHVmYLp6sEahuoDPfXWonKs/vf3kosdGarjrQvzXRsFjwzVsWfnRmMQSptGyJIn7uW9NmejpqmGqcpiWzZ65DcCeF5Vf6iqFwD8JYDbLRyXqPJMQefcXKurt3bnDe1676gqlMnpJmoS3v8dGaovCxppc7FrhtvB+sBvLF9n/P5dm3HivpsjA1LaCTimtg2ILJ330lXhm0+Y7maiVGngsQw2cuQNAK/4vv8RgA8HXyQiuwHsBoB169ZZOC1R+aJ6qsG8d5K9NO959FRoPnmoPoA9OzcueywsRxs1yOnN9tx3xybjwlLBPPO269fi6JmZpbXOL6nXQpfHDTLlj/2ph817vwGgO/3Syzp+VRp4LENh5YeqekhVR1V1dO3a8NIsItck7amabv33Pn468jWeO2/ovoUPy9F+8qZ1kXtvRuWgw/LMXzn28tL3s3MtvN1axMFdm/H0xPbIHnyS/PG5ufB69uDjSdahWelT9m30yJsArvZ9f1XnMaK+l3SquOkW/43zraXAFLWLvamcMSxHO3rN5cZKk6i2JBmgTLt0QNTrkvSik86eXGnrjwfZCOTfAfB+EbkW7QD+CQD/2sJxiZyQZMAravebvY+fxtsxlSZpd3Qf29KIXAY2yzls5Z2TlO+lGcSsysBjGTIHclWdF5HfA3AEwACAL6vq6Zi3ETkhS23y5HQTex473bWYVVDYuidBlw2lHwBMW+cc9WHj583szNrjTdKLLmMQsyoLYaVhZUKQqn4dwNdtHCsPLv7DUPmyLIo0Od3E+EMn0Vq0swOXoZAlUtp0Q5Kt1jy2FoiykX6xqUoLYaXR9zM7Xf2HofJlqU0+cORs4iAuEl+pMRvRa4/qqKStiZ566XV89ZlXsKCKARHcdN0avPjTudQzO20pevZknrsj5anvF82q0gpl5JYst/Vpbv2TlNuZeqC2ZjR6x3rkeHOp/HFBFc++fM64ABiQf5120bMnXa1H7/seuav/MFS+LLf1SfPNfl7PPFgLHtUDtdmDNB3rq8+8YnhHMXXaRQ5iulqP3vc9cu7tR73KUps8vmMD6rV0iW1V4MX9t+Lgrs1Y45vduHrQ/Gdqs6Nieo9pwSsAfVen7Wo9et8Hclf/YShcr5sU9yLLbf3YlgZ23Xh17OtM3nxnfunr2bkWxh8+Gfqz2uyoRE2rD7NmuF7pvHEvqrQQVhp9n1pZ6RMF+knYwPVdh09g6qXX8cWxTbmcM/j7442t+KfVh/1u/cHkKXzl2MupzuVtoLz38dNdi1q1FhR7Hz+NsS2NZee8bKiO+oAse32vHRXTwOKdNzTwyPFm1+P33bYx7DDOc7EeXbSXhQ0yGh0d1ampqcLPS24zTXAB4lfv69UfTJ7CA8de7spZ77uj/cFhCnxpg7inEZNbv3/X5q5z1muCd10ymGgNlDimDyaW8FaDiBxX1dGuxxnIyRXXTjwRuetNvSY48PEPWgswk9NN3HX4ROg5G500RFjQHQjZDSeMF7TT7OZjCvSNkSHjQljUP0yBvO9TK9Q/4ipBWouKPY+dtra7zIEjZ40BNmowMUkQHxDBj2fnEgd9oH3XwSosCtP3g53UP8Z3bDDuVOOZnWstGwRNMjhqqsWO+tCoiRiDvGlw0G9BFYpkQR9o323s2bmRVVgVUOSAe1LskZMzvJmHwZx1kBeIp156fdkgnWlWr6l+Oqq3bHrcy5Ef/vYroTM7awIkmfA5MlTHpasHQ3PSVdknciWq6kxxBnJyyhfHNmH0msvx+w+eiAyI3kSWsJ3bg5Nlouqng9u1RWn4Au7oNZcvWzBrzXAd9922EXcZNlX28zaRMO0TCbAKqyxVncLPQE5dwvLFQHWCh3fe8YdPdpXp+Zl6zcHAbcq9N3y5cu/nNqVbBFg22GgqYTOtEz4ggkXVRNfWxfK4flHVMQoGclom7NZx/OGTgGIpVWDjdjJrOZu/Z2oKrqbUSDCfHLUwUzBopl3jOyjJFmhUXVWdws/Bzj5hawAm7NaxtaBd+d4sC4/ZWuhpbEsDT09sx/27NofO3v3ND1+daFZvmtl8WWcKuzpzcKXz/r68clG/KoxRsEfeB2wOwKRZ6KnX20nbecaovLG37Vlczz9pusJGjpqpEbcE/74UFxc2a1RkjIKBvA/YCoyT081Uk1PibidN6ZM88oxecPTO+bnDJ3D3gyexoIrGyBAO7tps7Y+tnwIxZ2zGC/v78oJ4VSZhMZD3AVuBMWoCTJiodaqj7hLyyjMGz+nlx6tSIlY1VS2lq5qqDnD6MZD3AVuBMe0vpn9n92DP7q135kPvEu5+8CR+88NXhy7CFJVnTNJzjNoF3kaJWL/1XqtaSlc1VR3g9GMgd5Q/qIwM11GvybIByV4GYNJuhuAF/rCencmCKh453sSdNzRw9MxMoqAYWknz0Ensffz0soWi4j6IsvSg+rH36kJPswqK3m6uFwzkDgoGlTfOt1AfEIwM1XFurvcV8Ey/sKsHa6E7wXs9kqiecJi51gKOnplJnF8MraRZ1KXd573APjJcj9yRvped6KPa4Hrv1YWeZhW4MAmLgdxBphLBS1cP4sR9N/d8XNMvLBA9LdzmbjS9vra1qHjzbXMQB4C3LsxjcrrZ0x9gP/ZeXehpVkXVB7gZyB2UZ1AJ+4WdnG5i9WBt6Q/em27uvc7Us1szXMfP5uYTTcqJkjTl01qMeX5Bl/Wg0+S8+7H36kJPk5JhIHdQkUElmMYBgLcDEdPUs/N2kEnb6wsG2PXvTr+RsUlUXj8q592vvdeq9zQpGQZyBxUZVJLkhpP07JL0+ianm9j7+Ollee7m7JzV9EVUXj8q583eK1XZigrkrpaPhbV73x2bCvlZkqZxonp2SXp9YT1/j609rJLk9aM+NNh7papaMYHc1fIxU7v33bHJ6qwy04dcUWmctJUvJmuG6xheNbi0MbEIQvey7MecN61cKyaQu1o+VkS7gxsM+z/kikrjxKVPgksH1GsCCLp2j/cPwkbp15w3rUyZArmIHABwG4ALAH4A4N+p6qyNhtnmavlY3u2enG6G7rjjfVh4vf6saZy4tFZUZYq3605wAlGWdjHnTf0ka4/8mwDuUdV5EfkSgHsA/JfszbLP1Vvpy4bqoZNxskxu8UuywXDW3HCStFZYDxlob3lm2i3H//5eMOdN/SLTeuSq+g1Vne98ewzAVdmblI+s60iXxbSPb4L9fROJ6tnb+pCLSg95wtbpvn/XZpy472YGW6IYNnPkvw3gsOlJEdkNYDcArFu3zuJpk3H1VnrWMOXc9HhapjsVAax9yNmofCEis9hALiJPArgy5Kl7VfVrndfcC2AewAOm46jqIQCHAGB0dNRWRVkqLgaKvFNCppSGAks95qzXzNW0FpErYlMrqvoRVf2nIf95QfzTAD4G4JOqht1uqWd5p4T8KQ0Ay7ax6nULtiBX01pErsiUIxeRjwL4PICdqnreTpPIr4g9Hr29LxsjQ8bqlazH7/VnsLUXKVE/kyydaBF5HsBqAD/tPHRMVT8T977R0VGdmprq+byUj2snnjBWsAiQelwh60zasNme3HGeVjIROa6qo8HHMw12quovZnn/ShIX1KqwfEBULbd/t3sgPm9uYyatq5O4iIqWKbXisiy37Gnf6wW15uzcsoDovS/u+aKE5bKDkqZakpQcxnF1EhdR0Zydop+lB5ult2h679RLrxu3LovrWVal5xks0YybKBTFRhBmtQtRMk72yLP2YLP0Fk3v/cqxl43tiQtqVep5egOfL+y/damSJShJIDW9Jk0QHt+xob2mik+9Jqx2IQpwMpBnvW3PEjiTBld/e+KCmo2gl4csZYPWSg6DM1gtzWgl6idOBnJTME26i0yWwJkmuHrtjAtqcc+XVYKXpWzQRtnkgSNnl61uCFzcro2ILnIyRx41rTzJ5rpZljA1zYQ0tROIXx4g6vk811FPMs6QZTZs8OdKO1O0SiknoipzMpCP79iAuw6f6BqM86aVxwWKLOuu+N8bdQcQ/GCIC4im520NhAaD9rbr1+KR481cN9rI+iHEwU6iZDJNCOqVjQlB6yeeCH1cALyw/9ZMx07KtD1ZcJd577W9fHCYJumk+TnD2hncqMHTGBmytvPQ1v1PhQbipOfghCCi5XKZEFSmRgV6a0l79ll6pjZ6pWG9+iylhUllTY24umIlUdGcDeR5b9WVdibmwV2bjQEmS3ok7c/ptas5O4cBESykvOOy+UFo40PIxRUriYrmTNVKsHIDQG6LSdmeiZmlZ5qm+sPfLgCxQTxYyWd7RUKuekhUDCdy5ElypTbXKjHldr0d2k2DnKbcb9ZccVKm84QJ2wdz2/VrjbNTe1WFNWSI+oXTOfK41ITtEj1TT/mN8y28EbEzj+l9VdmJHjCvYphXmWPS1AgDPlHvnEitxKUmbCzQ5Ndrntj0viLWFI86v0cAHNy1GU9PbO86t+1rmEZVFg0jcpUTgTxuJmaaHHTULEnvuebsXOqZ4EkGIPPubcatXujfvi2ozMk3ZX6IEPUDJ1IrcamJpNURUekDAMueU1ystW6MDOGtd+YxOxeeVmlEBOc8Z2YGJZmsZArMZU6+4QxOomyc6JHHpSaSVkdE9fxMtdbegOSenRtDz3G/IVWR5Jx58G/bFkaB0PVayqwwqeqiYUSucKJHDkQPmiWdONJLz897Lsk5wlIoZfU2o9aECbsrKHPyTVGDwUT9yonyQ1uiygCB8NUTs04nXz1YC03JDIhgUTXXgOmfHBTGdvljFqxaIYrndPmhLXE9vyy9QlMK5ZJ6DUP1ga7nvMk6eefMx7Y0jOu1JK05LwJncBL1zokcuS1RufbgcyNDdVxSr+GuwycSrQFuSpXMnm8tO+6AdNfD2M6ZBytzLhuqh77OW/aXiNy2olIrSSVddc+fDqgZ1jUJpi9MvWNg+WQdoLd8dVjb6wPStUGDqX1EVF1MrQRE5WSTLHIVDJhhQTwsNWMq8wOwNBlm/KGTgGAp+KZJv4S13RTEAZb4EfUD51IrNrY9i5tJGLWVnPeasIAJtFMnUbM34ybtAEBrUbuCb9L0S9rAzBI/Ivc51SO3Nbkmrscd1Wv2zmcKmIuqkRs+BMv80iS2kgRpU9vXDNfxdmuRJX5EfcipHrmtyTVxtd3jOzagXgufpO+dL8skFm/Szgv7bzVO3Ik6dtRdiWliz323bSxkvRciKp5TPXJbk2vipqOPbWlg7+OnjSsd/nh2Dgd3bbYyiSWsJLImwGKgq+4dO+6uJOlGz0TUP5wK5LbWA0kyk3A2YrnakeH60t2BtwtP1HorUYKBd2S4jjffnseib/BUANx5QztIb93/VOxALGuyiVYWK6kVEblbRFRErrBxPBNb64EkWVY26sPhzbfnl+3C47Wh1+DpT7UMrxpEK9AdVwBHz8wA4AJTRNQtc49cRK4GcDOAl7M3J5rN9UCieq2T00289c581+MC4JJ6DXOtxWWPJ91/M4m4QF3mKoVEVE02UisHAXwewNcsHCtW3mmDsAk1QLvq477bNuKuwydC3+cPwFnWDYkL1FxgioiCMqVWROR2AE1VPZngtbtFZEpEpmZmZrKcNlem+vDhVYNLpYlh/BUlWXa7iUsfFbXbEBG5I7ZHLiJPArgy5Kl7AfxXtNMqsVT1EIBDQHuKfoo2FipJaWJUjzjJrNAoSdJHHMwkIr/YQK6qHwl7XEQ2AbgWwElpLwR1FYBnReRGVf17q60sUJLSRMAcaG0MRjJQE1EaPefIVfUUgPd434vIiwBGVfUnFtpVmiQ56KhAy8FIIiqaU3XkReilMsY/uDkyXEe9JstKCDkYSUR5shbIVXW9rWOVLU1qI1jl8sb5FuoDgpGhOs7NtbjbDRHljj3yjEzLxl66ehAn7ks0DkxElAkDeUZlzLTk/pZE5OfU6odVlGUVxF5krVMnov7DQJ6RrfVfkrK1lC8R9Q+nUytVSDHYXP8lCS6aRURBzgZyW7sF2VDkBB7WqRNRkLOplaqnGGzsLRqm6FQOEVWfsz3yqBRD2SmXPO8Wik7lEFH1iWrx61eNjo7q1NRUpmNs3f9Uqk2G77yhgaNnZgoJfqa2NUaG8PTE9lzOSUT9T0SOq+po8HFnUyumFIMqQlMuDxx7ubCSPQ5IElGRnA3kpnW5z82F77UZvO/IM59edG05Ea1szubIgfBqkQNHzoamNcLk1UPmLj5EVCRne+QmYSkXMbw2rx6y6W4BQC6VLES0sjndIw8TVtWx7fq1eOR4s9AecvBuoUp170TUX/oukAPhKZfRay4vtWQv6xZwREQmfRnIw5S9fRorWYgoL32XI68qVrIQUV6cDuR5TYPPA6fWE1FenE2tuDZ4yKn1RJQXZwO5i4OHZefpiag/OZta4eAhEVGbs4Gcg4dERG3OBnIOHhIRtTmbI+fgIRFRm7OBHODgIRER4HBqhYiI2hjIiYgcx0BOROS4zIFcRP6ziJwRkdMi8oc2GkVERMllGuwUkW0AbgfwQVV9R0TeY6dZRESUVNYe+e8C2K+q7wCAqr6WvUlERJRG1kD+SwD+uYg8IyL/R0R+2fRCEdktIlMiMjUzM5PxtERE5IlNrYjIkwCuDHnq3s77LwdwE4BfBvCgiFynqsFN66GqhwAcAoDR0dGu54mIqDexgVxVP2J6TkR+F8CjncD9bRFZBHAFAHa5iYgKkjW1MglgGwCIyC8BWAXgJ1kbRUREyWWdov9lAF8Wke8BuADgU2FpFSIiyk+mQK6qFwD8lqW2pDI53eSCWUREcHTRLNe2eSMiypOTU/SjtnkjIlppnAzk3OaNiOgiJwM5t3kjIrrIyUDObd6IiC5ycrCT27wREV3kZCAHuM0bEZHHydQKERFdxEBOROQ4BnIiIscxkBMROY6BnIjIcVLGYoUiMgPgpR7eegWquUwu25VeVdvGdqVT1XYB1W1blnZdo6prgw+WEsh7JSJTqjpadjuC2K70qto2tiudqrYLqG7b8mgXUytERI5jICcicpxrgfxQ2eFALJAAAATGSURBVA0wYLvSq2rb2K50qtouoLpts94up3LkRETUzbUeORERBTCQExE5rtKBXEQOiMgZEfmuiPyViIwYXvdRETkrIs+LyEQB7fq4iJwWkUURMZYRiciLInJKRE6IyFSF2lXo9eqc83IR+aaI/F3n/2sMr1voXK8TIvJYju2JvAYislpEDneef0ZE1ufVlpTt+rSIzPiu0b8vqF1fFpHXROR7hudFRP640+7visiHKtKuXxORc77r9YWC2nW1iBwVke93/iY/G/Iae9dMVSv7H4CbAQx2vv4SgC+FvGYAwA8AXAdgFYCTAD6Qc7v+CYANAL4FYDTidS8CuKLA6xXbrjKuV+e8fwhgovP1RNi/Zee5NwtoS+w1APAfAfyvztefAHC4Iu36NID/UdTvlO+8/wLAhwB8z/D8LQD+BoAAuAnAMxVp168B+OsSrtd7AXyo8/XPAfjbkH9La9es0j1yVf2Gqs53vj0G4KqQl90I4HlV/aGqXgDwlwBuz7ldz6lq5XZ6Ttiuwq9Xx+0A/rzz9Z8DGCvgnCZJroG/vQ8D+HURkQq0qxSq+n8BvB7xktsB/IW2HQMwIiLvrUC7SqGqr6rqs52v/xHAcwCCGyhYu2aVDuQBv432p1dQA8Arvu9/hO4LVhYF8A0ROS4iu8tuTEdZ1+sXVPXVztd/D+AXDK+7RESmROSYiOQV7JNcg6XXdDoT5wC8O6f2pGkXANzZuRV/WESuzrlNSVX57/CfichJEfkbEdlY9Mk7abktAJ4JPGXtmpW+Q5CIPAngypCn7lXVr3Vecy+AeQAPVKldCfyqqjZF5D0AvikiZzo9iLLblYuotvm/UVUVEVPd6zWda3YdgKdE5JSq/sB2Wx32OICvquo7IvIf0L5r2F5ym6rsWbR/p94UkVsATAJ4f1EnF5F3AXgEwOdU9Wd5naf0QK6qH4l6XkQ+DeBjAH5dO4mlgCYAf6/kqs5jubYr4TGanf+/JiJ/hfatc6ZAbqFduVwvILptIvIPIvJeVX21c/v4muEY3jX7oYh8C+2ejO1AnuQaeK/5kYgMArgMwE8ttyN1u1TV34Y/RXvsoQpy+73Kwh88VfXrIvI/ReQKVc19MS0RqaMdxB9Q1UdDXmLtmlU6tSIiHwXweQA7VfW84WXfAfB+EblWRFahPTCVW7VDUiJyqYj8nPc12gO3oSPrBSvrej0G4FOdrz8FoOvuQUTWiMjqztdXANgK4Ps5tCXJNfC39zcAPGXoSBTarkAOdSfaudcqeAzAv+1UYtwE4JwvlVYaEbnSG9sQkRvRjnl5fyCjc84/A/Ccqv6R4WX2rlnRo7kpR36fRzuHdKLzn1dF8D4AXw+M/v4t2j23ewto179CO5/1DoB/AHAk2C60Kw9Odv47XZV2lXG9Oud8N4D/DeDvADwJ4PLO46MA/rTz9a8AONW5ZqcA/E6O7em6BgD+G9qdBgC4BMBDnd/BbwO4rqDrFNeufZ3fp5MAjgK4vqB2fRXAqwBand+x3wHwGQCf6TwvAP6k0+5TiKjmKrhdv+e7XscA/EpB7fpVtMfIvuuLX7fkdc04RZ+IyHGVTq0QEVE8BnIiIscxkBMROY6BnIjIcQzkRESOYyAnInIcAzkRkeP+PxjnENG6lOjAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x[:150], y[:150]\n",
    "x_test, y_test = x[150:], y[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 7.0625 - val_loss: 4.2428\n",
      "Epoch 2/500\n",
      "105/105 [==============================] - 0s 203us/sample - loss: 5.8079 - val_loss: 3.5716\n",
      "Epoch 3/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 4.7899 - val_loss: 3.0613\n",
      "Epoch 4/500\n",
      "105/105 [==============================] - 0s 279us/sample - loss: 3.9899 - val_loss: 2.6377\n",
      "Epoch 5/500\n",
      "105/105 [==============================] - 0s 280us/sample - loss: 3.3573 - val_loss: 2.3188\n",
      "Epoch 6/500\n",
      "105/105 [==============================] - 0s 251us/sample - loss: 2.8716 - val_loss: 2.0676\n",
      "Epoch 7/500\n",
      "105/105 [==============================] - 0s 315us/sample - loss: 2.4903 - val_loss: 1.8788\n",
      "Epoch 8/500\n",
      "105/105 [==============================] - 0s 294us/sample - loss: 2.1937 - val_loss: 1.7048\n",
      "Epoch 9/500\n",
      "105/105 [==============================] - 0s 267us/sample - loss: 1.9251 - val_loss: 1.5495\n",
      "Epoch 10/500\n",
      "105/105 [==============================] - 0s 233us/sample - loss: 1.6875 - val_loss: 1.4137\n",
      "Epoch 11/500\n",
      "105/105 [==============================] - 0s 240us/sample - loss: 1.4967 - val_loss: 1.3190\n",
      "Epoch 12/500\n",
      "105/105 [==============================] - 0s 237us/sample - loss: 1.3588 - val_loss: 1.2450\n",
      "Epoch 13/500\n",
      "105/105 [==============================] - 0s 252us/sample - loss: 1.2473 - val_loss: 1.1794\n",
      "Epoch 14/500\n",
      "105/105 [==============================] - 0s 273us/sample - loss: 1.1551 - val_loss: 1.1317\n",
      "Epoch 15/500\n",
      "105/105 [==============================] - 0s 286us/sample - loss: 1.0826 - val_loss: 1.0839\n",
      "Epoch 16/500\n",
      "105/105 [==============================] - 0s 282us/sample - loss: 1.0132 - val_loss: 1.0467\n",
      "Epoch 17/500\n",
      "105/105 [==============================] - 0s 295us/sample - loss: 0.9605 - val_loss: 1.0264\n",
      "Epoch 18/500\n",
      "105/105 [==============================] - 0s 242us/sample - loss: 0.9273 - val_loss: 1.0107\n",
      "Epoch 19/500\n",
      "105/105 [==============================] - 0s 280us/sample - loss: 0.8968 - val_loss: 0.9947\n",
      "Epoch 20/500\n",
      "105/105 [==============================] - 0s 230us/sample - loss: 0.8717 - val_loss: 0.9750\n",
      "Epoch 21/500\n",
      "105/105 [==============================] - 0s 234us/sample - loss: 0.8469 - val_loss: 0.9601\n",
      "Epoch 22/500\n",
      "105/105 [==============================] - 0s 263us/sample - loss: 0.8254 - val_loss: 0.9469\n",
      "Epoch 23/500\n",
      "105/105 [==============================] - 0s 267us/sample - loss: 0.8117 - val_loss: 0.9417\n",
      "Epoch 24/500\n",
      "105/105 [==============================] - 0s 231us/sample - loss: 0.8012 - val_loss: 0.9401\n",
      "Epoch 25/500\n",
      "105/105 [==============================] - 0s 271us/sample - loss: 0.7966 - val_loss: 0.9338\n",
      "Epoch 26/500\n",
      "105/105 [==============================] - 0s 251us/sample - loss: 0.7894 - val_loss: 0.9293\n",
      "Epoch 27/500\n",
      "105/105 [==============================] - 0s 225us/sample - loss: 0.7850 - val_loss: 0.9248\n",
      "Epoch 28/500\n",
      "105/105 [==============================] - 0s 221us/sample - loss: 0.7795 - val_loss: 0.9227\n",
      "Epoch 29/500\n",
      "105/105 [==============================] - 0s 228us/sample - loss: 0.7763 - val_loss: 0.9183\n",
      "Epoch 30/500\n",
      "105/105 [==============================] - 0s 218us/sample - loss: 0.7711 - val_loss: 0.9140\n",
      "Epoch 31/500\n",
      "105/105 [==============================] - 0s 246us/sample - loss: 0.7673 - val_loss: 0.9145\n",
      "Epoch 32/500\n",
      "105/105 [==============================] - 0s 220us/sample - loss: 0.7668 - val_loss: 0.9119\n",
      "Epoch 33/500\n",
      "105/105 [==============================] - 0s 252us/sample - loss: 0.7644 - val_loss: 0.9105\n",
      "Epoch 34/500\n",
      "105/105 [==============================] - 0s 256us/sample - loss: 0.7632 - val_loss: 0.9029\n",
      "Epoch 35/500\n",
      "105/105 [==============================] - 0s 232us/sample - loss: 0.7606 - val_loss: 0.9067\n",
      "Epoch 36/500\n",
      "105/105 [==============================] - 0s 242us/sample - loss: 0.7612 - val_loss: 0.9133\n",
      "Epoch 37/500\n",
      "105/105 [==============================] - 0s 267us/sample - loss: 0.7604 - val_loss: 0.9121\n",
      "Epoch 38/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7606 - val_loss: 0.9130\n",
      "Epoch 39/500\n",
      "105/105 [==============================] - 0s 242us/sample - loss: 0.7619 - val_loss: 0.9104\n",
      "Epoch 40/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7598 - val_loss: 0.9088\n",
      "Epoch 41/500\n",
      "105/105 [==============================] - 0s 216us/sample - loss: 0.7589 - val_loss: 0.9091\n",
      "Epoch 42/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7576 - val_loss: 0.9104\n",
      "Epoch 43/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7578 - val_loss: 0.9053\n",
      "Epoch 44/500\n",
      "105/105 [==============================] - 0s 245us/sample - loss: 0.7591 - val_loss: 0.9061\n",
      "Epoch 45/500\n",
      "105/105 [==============================] - 0s 237us/sample - loss: 0.7572 - val_loss: 0.9067\n",
      "Epoch 46/500\n",
      "105/105 [==============================] - 0s 227us/sample - loss: 0.7580 - val_loss: 0.9044\n",
      "Epoch 47/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7564 - val_loss: 0.9019\n",
      "Epoch 48/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7564 - val_loss: 0.9025\n",
      "Epoch 49/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7566 - val_loss: 0.9068\n",
      "Epoch 50/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7568 - val_loss: 0.9019\n",
      "Epoch 51/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7573 - val_loss: 0.9042\n",
      "Epoch 52/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7565 - val_loss: 0.8999\n",
      "Epoch 53/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7562 - val_loss: 0.8998\n",
      "Epoch 54/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7561 - val_loss: 0.9011\n",
      "Epoch 55/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7571 - val_loss: 0.9047\n",
      "Epoch 56/500\n",
      "105/105 [==============================] - 0s 215us/sample - loss: 0.7572 - val_loss: 0.9006\n",
      "Epoch 57/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7564 - val_loss: 0.9021\n",
      "Epoch 58/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7581 - val_loss: 0.8999\n",
      "Epoch 59/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7564 - val_loss: 0.8976\n",
      "Epoch 60/500\n",
      "105/105 [==============================] - 0s 211us/sample - loss: 0.7566 - val_loss: 0.8960\n",
      "Epoch 61/500\n",
      "105/105 [==============================] - 0s 238us/sample - loss: 0.7578 - val_loss: 0.9001\n",
      "Epoch 62/500\n",
      "105/105 [==============================] - 0s 341us/sample - loss: 0.7579 - val_loss: 0.8950\n",
      "Epoch 63/500\n",
      "105/105 [==============================] - 0s 316us/sample - loss: 0.7569 - val_loss: 0.8949\n",
      "Epoch 64/500\n",
      "105/105 [==============================] - 0s 307us/sample - loss: 0.7567 - val_loss: 0.8936\n",
      "Epoch 65/500\n",
      "105/105 [==============================] - 0s 324us/sample - loss: 0.7563 - val_loss: 0.8962\n",
      "Epoch 66/500\n",
      "105/105 [==============================] - 0s 259us/sample - loss: 0.7571 - val_loss: 0.8978\n",
      "Epoch 67/500\n",
      "105/105 [==============================] - 0s 265us/sample - loss: 0.7566 - val_loss: 0.8969\n",
      "Epoch 68/500\n",
      "105/105 [==============================] - 0s 292us/sample - loss: 0.7561 - val_loss: 0.8967\n",
      "Epoch 69/500\n",
      "105/105 [==============================] - 0s 280us/sample - loss: 0.7574 - val_loss: 0.8975\n",
      "Epoch 70/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7565 - val_loss: 0.8937\n",
      "Epoch 71/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7566 - val_loss: 0.8935\n",
      "Epoch 72/500\n",
      "105/105 [==============================] - 0s 217us/sample - loss: 0.7565 - val_loss: 0.8951\n",
      "Epoch 73/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7564 - val_loss: 0.8965\n",
      "Epoch 74/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7571 - val_loss: 0.8960\n",
      "Epoch 75/500\n",
      "105/105 [==============================] - 0s 213us/sample - loss: 0.7565 - val_loss: 0.8968\n",
      "Epoch 76/500\n",
      "105/105 [==============================] - 0s 169us/sample - loss: 0.7565 - val_loss: 0.8947\n",
      "Epoch 77/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7567 - val_loss: 0.8955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7577 - val_loss: 0.8999\n",
      "Epoch 79/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7560 - val_loss: 0.9019\n",
      "Epoch 80/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7563 - val_loss: 0.9012\n",
      "Epoch 81/500\n",
      "105/105 [==============================] - 0s 230us/sample - loss: 0.7573 - val_loss: 0.9042\n",
      "Epoch 82/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7566 - val_loss: 0.8985\n",
      "Epoch 83/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7560 - val_loss: 0.9002\n",
      "Epoch 84/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7560 - val_loss: 0.8972\n",
      "Epoch 85/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7578 - val_loss: 0.8953\n",
      "Epoch 86/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7565 - val_loss: 0.8961\n",
      "Epoch 87/500\n",
      "105/105 [==============================] - 0s 165us/sample - loss: 0.7565 - val_loss: 0.9005\n",
      "Epoch 88/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7569 - val_loss: 0.8970\n",
      "Epoch 89/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7560 - val_loss: 0.8970\n",
      "Epoch 90/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7562 - val_loss: 0.8943\n",
      "Epoch 91/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7566 - val_loss: 0.8942\n",
      "Epoch 92/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7568 - val_loss: 0.8970\n",
      "Epoch 93/500\n",
      "105/105 [==============================] - 0s 237us/sample - loss: 0.7560 - val_loss: 0.8979\n",
      "Epoch 94/500\n",
      "105/105 [==============================] - 0s 228us/sample - loss: 0.7559 - val_loss: 0.9002\n",
      "Epoch 95/500\n",
      "105/105 [==============================] - 0s 304us/sample - loss: 0.7572 - val_loss: 0.8979\n",
      "Epoch 96/500\n",
      "105/105 [==============================] - 0s 294us/sample - loss: 0.7570 - val_loss: 0.8988\n",
      "Epoch 97/500\n",
      "105/105 [==============================] - 0s 235us/sample - loss: 0.7562 - val_loss: 0.9015\n",
      "Epoch 98/500\n",
      "105/105 [==============================] - 0s 242us/sample - loss: 0.7571 - val_loss: 0.9002\n",
      "Epoch 99/500\n",
      "105/105 [==============================] - 0s 279us/sample - loss: 0.7590 - val_loss: 0.9027\n",
      "Epoch 100/500\n",
      "105/105 [==============================] - 0s 285us/sample - loss: 0.7567 - val_loss: 0.9071\n",
      "Epoch 101/500\n",
      "105/105 [==============================] - 0s 254us/sample - loss: 0.7575 - val_loss: 0.9095\n",
      "Epoch 102/500\n",
      "105/105 [==============================] - 0s 218us/sample - loss: 0.7581 - val_loss: 0.9148\n",
      "Epoch 103/500\n",
      "105/105 [==============================] - 0s 281us/sample - loss: 0.7584 - val_loss: 0.9104\n",
      "Epoch 104/500\n",
      "105/105 [==============================] - 0s 231us/sample - loss: 0.7594 - val_loss: 0.9111\n",
      "Epoch 105/500\n",
      "105/105 [==============================] - 0s 244us/sample - loss: 0.7578 - val_loss: 0.9090\n",
      "Epoch 106/500\n",
      "105/105 [==============================] - 0s 276us/sample - loss: 0.7566 - val_loss: 0.9095\n",
      "Epoch 107/500\n",
      "105/105 [==============================] - 0s 203us/sample - loss: 0.7564 - val_loss: 0.9085\n",
      "Epoch 108/500\n",
      "105/105 [==============================] - 0s 223us/sample - loss: 0.7570 - val_loss: 0.9063\n",
      "Epoch 109/500\n",
      "105/105 [==============================] - 0s 265us/sample - loss: 0.7561 - val_loss: 0.9073\n",
      "Epoch 110/500\n",
      "105/105 [==============================] - 0s 261us/sample - loss: 0.7560 - val_loss: 0.9097\n",
      "Epoch 111/500\n",
      "105/105 [==============================] - 0s 264us/sample - loss: 0.7564 - val_loss: 0.9075\n",
      "Epoch 112/500\n",
      "105/105 [==============================] - 0s 315us/sample - loss: 0.7565 - val_loss: 0.9051\n",
      "Epoch 113/500\n",
      "105/105 [==============================] - 0s 323us/sample - loss: 0.7561 - val_loss: 0.9033\n",
      "Epoch 114/500\n",
      "105/105 [==============================] - 0s 480us/sample - loss: 0.7559 - val_loss: 0.9026\n",
      "Epoch 115/500\n",
      "105/105 [==============================] - 0s 256us/sample - loss: 0.7568 - val_loss: 0.9054\n",
      "Epoch 116/500\n",
      "105/105 [==============================] - 0s 239us/sample - loss: 0.7559 - val_loss: 0.9035\n",
      "Epoch 117/500\n",
      "105/105 [==============================] - 0s 229us/sample - loss: 0.7566 - val_loss: 0.9004\n",
      "Epoch 118/500\n",
      "105/105 [==============================] - 0s 274us/sample - loss: 0.7567 - val_loss: 0.9002\n",
      "Epoch 119/500\n",
      "105/105 [==============================] - 0s 297us/sample - loss: 0.7561 - val_loss: 0.8973\n",
      "Epoch 120/500\n",
      "105/105 [==============================] - 0s 217us/sample - loss: 0.7564 - val_loss: 0.8979\n",
      "Epoch 121/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7579 - val_loss: 0.9038\n",
      "Epoch 122/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7560 - val_loss: 0.9057\n",
      "Epoch 123/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7598 - val_loss: 0.9084\n",
      "Epoch 124/500\n",
      "105/105 [==============================] - 0s 220us/sample - loss: 0.7567 - val_loss: 0.9078\n",
      "Epoch 125/500\n",
      "105/105 [==============================] - 0s 207us/sample - loss: 0.7567 - val_loss: 0.9069\n",
      "Epoch 126/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7573 - val_loss: 0.9051\n",
      "Epoch 127/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7563 - val_loss: 0.9053\n",
      "Epoch 128/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7574 - val_loss: 0.9019\n",
      "Epoch 129/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7579 - val_loss: 0.9019\n",
      "Epoch 130/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7562 - val_loss: 0.9012\n",
      "Epoch 131/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7566 - val_loss: 0.9000\n",
      "Epoch 132/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7564 - val_loss: 0.9015\n",
      "Epoch 133/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7566 - val_loss: 0.9089\n",
      "Epoch 134/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7566 - val_loss: 0.9089\n",
      "Epoch 135/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7575 - val_loss: 0.9113\n",
      "Epoch 136/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7583 - val_loss: 0.9079\n",
      "Epoch 137/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7565 - val_loss: 0.9091\n",
      "Epoch 138/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7570 - val_loss: 0.9044\n",
      "Epoch 139/500\n",
      "105/105 [==============================] - 0s 214us/sample - loss: 0.7569 - val_loss: 0.9046\n",
      "Epoch 140/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7567 - val_loss: 0.9089\n",
      "Epoch 141/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7564 - val_loss: 0.9075\n",
      "Epoch 142/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7566 - val_loss: 0.9017\n",
      "Epoch 143/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7558 - val_loss: 0.9022\n",
      "Epoch 144/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7560 - val_loss: 0.9032\n",
      "Epoch 145/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7558 - val_loss: 0.9033\n",
      "Epoch 146/500\n",
      "105/105 [==============================] - 0s 199us/sample - loss: 0.7560 - val_loss: 0.9047\n",
      "Epoch 147/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7570 - val_loss: 0.9039\n",
      "Epoch 148/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7558 - val_loss: 0.9082\n",
      "Epoch 149/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7573 - val_loss: 0.9094\n",
      "Epoch 150/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7573 - val_loss: 0.9061\n",
      "Epoch 151/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7558 - val_loss: 0.9059\n",
      "Epoch 152/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7560 - val_loss: 0.9020\n",
      "Epoch 153/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7577 - val_loss: 0.9091\n",
      "Epoch 154/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7572 - val_loss: 0.9054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7568 - val_loss: 0.9042\n",
      "Epoch 156/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7565 - val_loss: 0.9058\n",
      "Epoch 157/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7561 - val_loss: 0.9046\n",
      "Epoch 158/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7574 - val_loss: 0.9042\n",
      "Epoch 159/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7570 - val_loss: 0.9027\n",
      "Epoch 160/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7578 - val_loss: 0.9047\n",
      "Epoch 161/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7562 - val_loss: 0.9027\n",
      "Epoch 162/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7567 - val_loss: 0.9040\n",
      "Epoch 163/500\n",
      "105/105 [==============================] - 0s 257us/sample - loss: 0.7573 - val_loss: 0.9038\n",
      "Epoch 164/500\n",
      "105/105 [==============================] - 0s 244us/sample - loss: 0.7568 - val_loss: 0.9091\n",
      "Epoch 165/500\n",
      "105/105 [==============================] - 0s 301us/sample - loss: 0.7571 - val_loss: 0.9111\n",
      "Epoch 166/500\n",
      "105/105 [==============================] - 0s 282us/sample - loss: 0.7560 - val_loss: 0.9077\n",
      "Epoch 167/500\n",
      "105/105 [==============================] - 0s 288us/sample - loss: 0.7576 - val_loss: 0.9098\n",
      "Epoch 168/500\n",
      "105/105 [==============================] - 0s 251us/sample - loss: 0.7563 - val_loss: 0.9068\n",
      "Epoch 169/500\n",
      "105/105 [==============================] - 0s 213us/sample - loss: 0.7564 - val_loss: 0.9040\n",
      "Epoch 170/500\n",
      "105/105 [==============================] - 0s 211us/sample - loss: 0.7562 - val_loss: 0.9091\n",
      "Epoch 171/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7558 - val_loss: 0.9073\n",
      "Epoch 172/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7579 - val_loss: 0.9120\n",
      "Epoch 173/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7560 - val_loss: 0.9097\n",
      "Epoch 174/500\n",
      "105/105 [==============================] - 0s 229us/sample - loss: 0.7570 - val_loss: 0.9086\n",
      "Epoch 175/500\n",
      "105/105 [==============================] - 0s 209us/sample - loss: 0.7565 - val_loss: 0.9075\n",
      "Epoch 176/500\n",
      "105/105 [==============================] - 0s 227us/sample - loss: 0.7570 - val_loss: 0.9132\n",
      "Epoch 177/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7566 - val_loss: 0.9120\n",
      "Epoch 178/500\n",
      "105/105 [==============================] - 0s 237us/sample - loss: 0.7568 - val_loss: 0.9189\n",
      "Epoch 179/500\n",
      "105/105 [==============================] - 0s 237us/sample - loss: 0.7574 - val_loss: 0.9192\n",
      "Epoch 180/500\n",
      "105/105 [==============================] - 0s 226us/sample - loss: 0.7575 - val_loss: 0.9179\n",
      "Epoch 181/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7568 - val_loss: 0.9171\n",
      "Epoch 182/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7565 - val_loss: 0.9182\n",
      "Epoch 183/500\n",
      "105/105 [==============================] - 0s 230us/sample - loss: 0.7569 - val_loss: 0.9199\n",
      "Epoch 184/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7577 - val_loss: 0.9188\n",
      "Epoch 185/500\n",
      "105/105 [==============================] - 0s 169us/sample - loss: 0.7573 - val_loss: 0.9206\n",
      "Epoch 186/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7573 - val_loss: 0.9169\n",
      "Epoch 187/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7572 - val_loss: 0.9148\n",
      "Epoch 188/500\n",
      "105/105 [==============================] - 0s 216us/sample - loss: 0.7563 - val_loss: 0.9132\n",
      "Epoch 189/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7568 - val_loss: 0.9115\n",
      "Epoch 190/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7569 - val_loss: 0.9109\n",
      "Epoch 191/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7566 - val_loss: 0.9097\n",
      "Epoch 192/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7560 - val_loss: 0.9130\n",
      "Epoch 193/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7571 - val_loss: 0.9114\n",
      "Epoch 194/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7563 - val_loss: 0.9135\n",
      "Epoch 195/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7587 - val_loss: 0.9132\n",
      "Epoch 196/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7577 - val_loss: 0.9175\n",
      "Epoch 197/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7583 - val_loss: 0.9120\n",
      "Epoch 198/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7580 - val_loss: 0.9116\n",
      "Epoch 199/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7586 - val_loss: 0.9139\n",
      "Epoch 200/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7566 - val_loss: 0.9147\n",
      "Epoch 201/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7563 - val_loss: 0.9182\n",
      "Epoch 202/500\n",
      "105/105 [==============================] - 0s 205us/sample - loss: 0.7569 - val_loss: 0.9132\n",
      "Epoch 203/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7566 - val_loss: 0.9175\n",
      "Epoch 204/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7569 - val_loss: 0.9154\n",
      "Epoch 205/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7571 - val_loss: 0.9195\n",
      "Epoch 206/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7579 - val_loss: 0.9175\n",
      "Epoch 207/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7574 - val_loss: 0.9162\n",
      "Epoch 208/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7582 - val_loss: 0.9169\n",
      "Epoch 209/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7572 - val_loss: 0.9156\n",
      "Epoch 210/500\n",
      "105/105 [==============================] - 0s 201us/sample - loss: 0.7564 - val_loss: 0.9155\n",
      "Epoch 211/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7569 - val_loss: 0.9158\n",
      "Epoch 212/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7580 - val_loss: 0.9179\n",
      "Epoch 213/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7574 - val_loss: 0.9129\n",
      "Epoch 214/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7569 - val_loss: 0.9117\n",
      "Epoch 215/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7563 - val_loss: 0.9093\n",
      "Epoch 216/500\n",
      "105/105 [==============================] - 0s 191us/sample - loss: 0.7562 - val_loss: 0.9069\n",
      "Epoch 217/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7586 - val_loss: 0.9061\n",
      "Epoch 218/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7563 - val_loss: 0.9106\n",
      "Epoch 219/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7585 - val_loss: 0.9055\n",
      "Epoch 220/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7562 - val_loss: 0.9065\n",
      "Epoch 221/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7562 - val_loss: 0.9073\n",
      "Epoch 222/500\n",
      "105/105 [==============================] - 0s 199us/sample - loss: 0.7570 - val_loss: 0.9069\n",
      "Epoch 223/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7564 - val_loss: 0.9053\n",
      "Epoch 224/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7570 - val_loss: 0.9079\n",
      "Epoch 225/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7563 - val_loss: 0.9074\n",
      "Epoch 226/500\n",
      "105/105 [==============================] - 0s 199us/sample - loss: 0.7561 - val_loss: 0.9112\n",
      "Epoch 227/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7562 - val_loss: 0.9125\n",
      "Epoch 228/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7567 - val_loss: 0.9133\n",
      "Epoch 229/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7566 - val_loss: 0.9092\n",
      "Epoch 230/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7571 - val_loss: 0.9066\n",
      "Epoch 231/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7560 - val_loss: 0.9065\n",
      "Epoch 232/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7580 - val_loss: 0.9039\n",
      "Epoch 233/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7557 - val_loss: 0.9048\n",
      "Epoch 234/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7569 - val_loss: 0.9031\n",
      "Epoch 235/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7561 - val_loss: 0.9044\n",
      "Epoch 236/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7568 - val_loss: 0.9028\n",
      "Epoch 237/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7570 - val_loss: 0.9036\n",
      "Epoch 238/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7561 - val_loss: 0.9079\n",
      "Epoch 239/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7559 - val_loss: 0.9058\n",
      "Epoch 240/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7557 - val_loss: 0.9052\n",
      "Epoch 241/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7578 - val_loss: 0.9014\n",
      "Epoch 242/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7566 - val_loss: 0.8999\n",
      "Epoch 243/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7575 - val_loss: 0.8986\n",
      "Epoch 244/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7557 - val_loss: 0.8990\n",
      "Epoch 245/500\n",
      "105/105 [==============================] - 0s 207us/sample - loss: 0.7569 - val_loss: 0.9003\n",
      "Epoch 246/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7570 - val_loss: 0.8980\n",
      "Epoch 247/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7567 - val_loss: 0.8949\n",
      "Epoch 248/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7563 - val_loss: 0.8941\n",
      "Epoch 249/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7572 - val_loss: 0.8971\n",
      "Epoch 250/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7561 - val_loss: 0.8988\n",
      "Epoch 251/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7563 - val_loss: 0.9031\n",
      "Epoch 252/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7566 - val_loss: 0.9000\n",
      "Epoch 253/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7566 - val_loss: 0.8985\n",
      "Epoch 254/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7563 - val_loss: 0.8979\n",
      "Epoch 255/500\n",
      "105/105 [==============================] - 0s 213us/sample - loss: 0.7578 - val_loss: 0.8976\n",
      "Epoch 256/500\n",
      "105/105 [==============================] - 0s 169us/sample - loss: 0.7564 - val_loss: 0.8993\n",
      "Epoch 257/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7557 - val_loss: 0.8985\n",
      "Epoch 258/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7571 - val_loss: 0.9013\n",
      "Epoch 259/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7558 - val_loss: 0.9016\n",
      "Epoch 260/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7565 - val_loss: 0.9016\n",
      "Epoch 261/500\n",
      "105/105 [==============================] - 0s 164us/sample - loss: 0.7575 - val_loss: 0.9009\n",
      "Epoch 262/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7563 - val_loss: 0.8988\n",
      "Epoch 263/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7561 - val_loss: 0.9012\n",
      "Epoch 264/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7566 - val_loss: 0.8997\n",
      "Epoch 265/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7577 - val_loss: 0.8992\n",
      "Epoch 266/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7558 - val_loss: 0.9000\n",
      "Epoch 267/500\n",
      "105/105 [==============================] - 0s 205us/sample - loss: 0.7561 - val_loss: 0.9001\n",
      "Epoch 268/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7568 - val_loss: 0.8980\n",
      "Epoch 269/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7564 - val_loss: 0.8972\n",
      "Epoch 270/500\n",
      "105/105 [==============================] - 0s 205us/sample - loss: 0.7563 - val_loss: 0.8958\n",
      "Epoch 271/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7572 - val_loss: 0.8977\n",
      "Epoch 272/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7589 - val_loss: 0.8990\n",
      "Epoch 273/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7570 - val_loss: 0.8991\n",
      "Epoch 274/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7559 - val_loss: 0.8982\n",
      "Epoch 275/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7567 - val_loss: 0.8987\n",
      "Epoch 276/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7574 - val_loss: 0.9004\n",
      "Epoch 277/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7562 - val_loss: 0.8989\n",
      "Epoch 278/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7560 - val_loss: 0.9001\n",
      "Epoch 279/500\n",
      "105/105 [==============================] - 0s 165us/sample - loss: 0.7564 - val_loss: 0.9032\n",
      "Epoch 280/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7561 - val_loss: 0.9035\n",
      "Epoch 281/500\n",
      "105/105 [==============================] - 0s 219us/sample - loss: 0.7559 - val_loss: 0.9012\n",
      "Epoch 282/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7572 - val_loss: 0.9018\n",
      "Epoch 283/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7560 - val_loss: 0.9011\n",
      "Epoch 284/500\n",
      "105/105 [==============================] - 0s 165us/sample - loss: 0.7569 - val_loss: 0.9025\n",
      "Epoch 285/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7566 - val_loss: 0.8995\n",
      "Epoch 286/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7562 - val_loss: 0.8995\n",
      "Epoch 287/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7559 - val_loss: 0.8986\n",
      "Epoch 288/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7574 - val_loss: 0.8990\n",
      "Epoch 289/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7580 - val_loss: 0.8995\n",
      "Epoch 290/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7569 - val_loss: 0.8967\n",
      "Epoch 291/500\n",
      "105/105 [==============================] - 0s 207us/sample - loss: 0.7565 - val_loss: 0.8956\n",
      "Epoch 292/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7569 - val_loss: 0.9017\n",
      "Epoch 293/500\n",
      "105/105 [==============================] - 0s 199us/sample - loss: 0.7560 - val_loss: 0.9055\n",
      "Epoch 294/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7556 - val_loss: 0.9027\n",
      "Epoch 295/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7559 - val_loss: 0.9028\n",
      "Epoch 296/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7560 - val_loss: 0.9008\n",
      "Epoch 297/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7571 - val_loss: 0.9009\n",
      "Epoch 298/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7568 - val_loss: 0.9031\n",
      "Epoch 299/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7567 - val_loss: 0.9032\n",
      "Epoch 300/500\n",
      "105/105 [==============================] - 0s 191us/sample - loss: 0.7566 - val_loss: 0.9085\n",
      "Epoch 301/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7560 - val_loss: 0.9073\n",
      "Epoch 302/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7562 - val_loss: 0.9075\n",
      "Epoch 303/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7565 - val_loss: 0.9033\n",
      "Epoch 304/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7567 - val_loss: 0.9009\n",
      "Epoch 305/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7568 - val_loss: 0.9009\n",
      "Epoch 306/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7575 - val_loss: 0.9020\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7567 - val_loss: 0.9018\n",
      "Epoch 308/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7581 - val_loss: 0.9010\n",
      "Epoch 309/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7573 - val_loss: 0.9002\n",
      "Epoch 310/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7577 - val_loss: 0.9055\n",
      "Epoch 311/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7562 - val_loss: 0.9042\n",
      "Epoch 312/500\n",
      "105/105 [==============================] - 0s 169us/sample - loss: 0.7565 - val_loss: 0.9095\n",
      "Epoch 313/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7560 - val_loss: 0.9088\n",
      "Epoch 314/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7571 - val_loss: 0.9046\n",
      "Epoch 315/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7569 - val_loss: 0.9064\n",
      "Epoch 316/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7568 - val_loss: 0.9063\n",
      "Epoch 317/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7559 - val_loss: 0.9096\n",
      "Epoch 318/500\n",
      "105/105 [==============================] - 0s 220us/sample - loss: 0.7559 - val_loss: 0.9136\n",
      "Epoch 319/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7584 - val_loss: 0.9138\n",
      "Epoch 320/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7566 - val_loss: 0.9154\n",
      "Epoch 321/500\n",
      "105/105 [==============================] - 0s 165us/sample - loss: 0.7578 - val_loss: 0.9136\n",
      "Epoch 322/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7570 - val_loss: 0.9157\n",
      "Epoch 323/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7591 - val_loss: 0.9122\n",
      "Epoch 324/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7561 - val_loss: 0.9093\n",
      "Epoch 325/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7559 - val_loss: 0.9090\n",
      "Epoch 326/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7569 - val_loss: 0.9071\n",
      "Epoch 327/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7569 - val_loss: 0.9076\n",
      "Epoch 328/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7567 - val_loss: 0.9059\n",
      "Epoch 329/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7569 - val_loss: 0.9061\n",
      "Epoch 330/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7591 - val_loss: 0.9010\n",
      "Epoch 331/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7572 - val_loss: 0.9063\n",
      "Epoch 332/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7557 - val_loss: 0.9072\n",
      "Epoch 333/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7560 - val_loss: 0.9036\n",
      "Epoch 334/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7560 - val_loss: 0.9029\n",
      "Epoch 335/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7564 - val_loss: 0.9069\n",
      "Epoch 336/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7565 - val_loss: 0.9031\n",
      "Epoch 337/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7567 - val_loss: 0.9100\n",
      "Epoch 338/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7571 - val_loss: 0.9103\n",
      "Epoch 339/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7569 - val_loss: 0.9111\n",
      "Epoch 340/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7570 - val_loss: 0.9079\n",
      "Epoch 341/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7565 - val_loss: 0.9037\n",
      "Epoch 342/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7560 - val_loss: 0.9018\n",
      "Epoch 343/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7559 - val_loss: 0.9017\n",
      "Epoch 344/500\n",
      "105/105 [==============================] - 0s 164us/sample - loss: 0.7566 - val_loss: 0.9021\n",
      "Epoch 345/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7559 - val_loss: 0.9064\n",
      "Epoch 346/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7556 - val_loss: 0.9088\n",
      "Epoch 347/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7574 - val_loss: 0.9046\n",
      "Epoch 348/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7576 - val_loss: 0.9015\n",
      "Epoch 349/500\n",
      "105/105 [==============================] - 0s 161us/sample - loss: 0.7568 - val_loss: 0.8992\n",
      "Epoch 350/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7567 - val_loss: 0.8977\n",
      "Epoch 351/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7576 - val_loss: 0.8957\n",
      "Epoch 352/500\n",
      "105/105 [==============================] - 0s 210us/sample - loss: 0.7580 - val_loss: 0.8966\n",
      "Epoch 353/500\n",
      "105/105 [==============================] - 0s 169us/sample - loss: 0.7577 - val_loss: 0.8968\n",
      "Epoch 354/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7563 - val_loss: 0.8973\n",
      "Epoch 355/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7570 - val_loss: 0.8987\n",
      "Epoch 356/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7567 - val_loss: 0.9001\n",
      "Epoch 357/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7566 - val_loss: 0.9011\n",
      "Epoch 358/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7568 - val_loss: 0.9033\n",
      "Epoch 359/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7571 - val_loss: 0.9022\n",
      "Epoch 360/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7562 - val_loss: 0.9024\n",
      "Epoch 361/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7568 - val_loss: 0.9042\n",
      "Epoch 362/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7555 - val_loss: 0.9059\n",
      "Epoch 363/500\n",
      "105/105 [==============================] - 0s 213us/sample - loss: 0.7566 - val_loss: 0.9144\n",
      "Epoch 364/500\n",
      "105/105 [==============================] - 0s 191us/sample - loss: 0.7572 - val_loss: 0.9198\n",
      "Epoch 365/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7565 - val_loss: 0.9148\n",
      "Epoch 366/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7567 - val_loss: 0.9172\n",
      "Epoch 367/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7570 - val_loss: 0.9188\n",
      "Epoch 368/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7572 - val_loss: 0.9245\n",
      "Epoch 369/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7576 - val_loss: 0.9163\n",
      "Epoch 370/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7567 - val_loss: 0.9149\n",
      "Epoch 371/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7581 - val_loss: 0.9113\n",
      "Epoch 372/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7559 - val_loss: 0.9120\n",
      "Epoch 373/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7568 - val_loss: 0.9116\n",
      "Epoch 374/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7579 - val_loss: 0.9122\n",
      "Epoch 375/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7564 - val_loss: 0.9110\n",
      "Epoch 376/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7561 - val_loss: 0.9114\n",
      "Epoch 377/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7563 - val_loss: 0.9166\n",
      "Epoch 378/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7581 - val_loss: 0.9167\n",
      "Epoch 379/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7573 - val_loss: 0.9153\n",
      "Epoch 380/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7569 - val_loss: 0.9126\n",
      "Epoch 381/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7570 - val_loss: 0.9090\n",
      "Epoch 382/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7566 - val_loss: 0.9079\n",
      "Epoch 383/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7564 - val_loss: 0.9104\n",
      "Epoch 384/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7558 - val_loss: 0.9102\n",
      "Epoch 385/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7579 - val_loss: 0.9081\n",
      "Epoch 386/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7565 - val_loss: 0.9057\n",
      "Epoch 387/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7562 - val_loss: 0.9019\n",
      "Epoch 388/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7562 - val_loss: 0.9004\n",
      "Epoch 389/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7559 - val_loss: 0.8992\n",
      "Epoch 390/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7559 - val_loss: 0.8988\n",
      "Epoch 391/500\n",
      "105/105 [==============================] - 0s 162us/sample - loss: 0.7559 - val_loss: 0.8996\n",
      "Epoch 392/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7599 - val_loss: 0.8989\n",
      "Epoch 393/500\n",
      "105/105 [==============================] - 0s 205us/sample - loss: 0.7560 - val_loss: 0.8970\n",
      "Epoch 394/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7573 - val_loss: 0.8968\n",
      "Epoch 395/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7568 - val_loss: 0.8982\n",
      "Epoch 396/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7573 - val_loss: 0.9023\n",
      "Epoch 397/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7577 - val_loss: 0.9073\n",
      "Epoch 398/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7560 - val_loss: 0.9076\n",
      "Epoch 399/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7564 - val_loss: 0.9044\n",
      "Epoch 400/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7561 - val_loss: 0.9053\n",
      "Epoch 401/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7569 - val_loss: 0.9084\n",
      "Epoch 402/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7564 - val_loss: 0.9081\n",
      "Epoch 403/500\n",
      "105/105 [==============================] - 0s 199us/sample - loss: 0.7570 - val_loss: 0.9075\n",
      "Epoch 404/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7566 - val_loss: 0.9104\n",
      "Epoch 405/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7560 - val_loss: 0.9102\n",
      "Epoch 406/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7569 - val_loss: 0.9090\n",
      "Epoch 407/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7564 - val_loss: 0.9071\n",
      "Epoch 408/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7565 - val_loss: 0.9052\n",
      "Epoch 409/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7559 - val_loss: 0.9073\n",
      "Epoch 410/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7569 - val_loss: 0.9129\n",
      "Epoch 411/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7569 - val_loss: 0.9111\n",
      "Epoch 412/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7574 - val_loss: 0.9083\n",
      "Epoch 413/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7563 - val_loss: 0.9085\n",
      "Epoch 414/500\n",
      "105/105 [==============================] - 0s 191us/sample - loss: 0.7579 - val_loss: 0.9066\n",
      "Epoch 415/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7567 - val_loss: 0.9082\n",
      "Epoch 416/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7579 - val_loss: 0.9059\n",
      "Epoch 417/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7560 - val_loss: 0.9059\n",
      "Epoch 418/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7567 - val_loss: 0.9065\n",
      "Epoch 419/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7559 - val_loss: 0.9081\n",
      "Epoch 420/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7561 - val_loss: 0.9061\n",
      "Epoch 421/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7565 - val_loss: 0.9065\n",
      "Epoch 422/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7562 - val_loss: 0.9060\n",
      "Epoch 423/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7559 - val_loss: 0.9061\n",
      "Epoch 424/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7582 - val_loss: 0.9101\n",
      "Epoch 425/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7573 - val_loss: 0.9113\n",
      "Epoch 426/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7575 - val_loss: 0.9103\n",
      "Epoch 427/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7560 - val_loss: 0.9104\n",
      "Epoch 428/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7560 - val_loss: 0.9105\n",
      "Epoch 429/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7566 - val_loss: 0.9107\n",
      "Epoch 430/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7564 - val_loss: 0.9097\n",
      "Epoch 431/500\n",
      "105/105 [==============================] - 0s 199us/sample - loss: 0.7583 - val_loss: 0.9101\n",
      "Epoch 432/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7562 - val_loss: 0.9093\n",
      "Epoch 433/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7568 - val_loss: 0.9078\n",
      "Epoch 434/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7562 - val_loss: 0.9105\n",
      "Epoch 435/500\n",
      "105/105 [==============================] - 0s 191us/sample - loss: 0.7567 - val_loss: 0.9088\n",
      "Epoch 436/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7562 - val_loss: 0.9121\n",
      "Epoch 437/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7564 - val_loss: 0.9150\n",
      "Epoch 438/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7566 - val_loss: 0.9108\n",
      "Epoch 439/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7560 - val_loss: 0.9080\n",
      "Epoch 440/500\n",
      "105/105 [==============================] - 0s 211us/sample - loss: 0.7557 - val_loss: 0.9081\n",
      "Epoch 441/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7572 - val_loss: 0.9135\n",
      "Epoch 442/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7569 - val_loss: 0.9155\n",
      "Epoch 443/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7573 - val_loss: 0.9138\n",
      "Epoch 444/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7565 - val_loss: 0.9169\n",
      "Epoch 445/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7567 - val_loss: 0.9130\n",
      "Epoch 446/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7564 - val_loss: 0.9090\n",
      "Epoch 447/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7572 - val_loss: 0.9089\n",
      "Epoch 448/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7566 - val_loss: 0.9107\n",
      "Epoch 449/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7563 - val_loss: 0.9070\n",
      "Epoch 450/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7569 - val_loss: 0.9115\n",
      "Epoch 451/500\n",
      "105/105 [==============================] - 0s 201us/sample - loss: 0.7569 - val_loss: 0.9109\n",
      "Epoch 452/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7565 - val_loss: 0.9097\n",
      "Epoch 453/500\n",
      "105/105 [==============================] - 0s 207us/sample - loss: 0.7559 - val_loss: 0.9074\n",
      "Epoch 454/500\n",
      "105/105 [==============================] - 0s 169us/sample - loss: 0.7582 - val_loss: 0.9075\n",
      "Epoch 455/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7567 - val_loss: 0.9067\n",
      "Epoch 456/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7568 - val_loss: 0.9010\n",
      "Epoch 457/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7563 - val_loss: 0.9010\n",
      "Epoch 458/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7564 - val_loss: 0.8990\n",
      "Epoch 459/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7566 - val_loss: 0.9024\n",
      "Epoch 460/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7567 - val_loss: 0.9087\n",
      "Epoch 461/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7562 - val_loss: 0.9063\n",
      "Epoch 462/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7561 - val_loss: 0.9064\n",
      "Epoch 463/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7574 - val_loss: 0.9082\n",
      "Epoch 464/500\n",
      "105/105 [==============================] - 0s 191us/sample - loss: 0.7564 - val_loss: 0.9073\n",
      "Epoch 465/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7570 - val_loss: 0.9044\n",
      "Epoch 466/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7564 - val_loss: 0.9082\n",
      "Epoch 467/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7571 - val_loss: 0.9097\n",
      "Epoch 468/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7563 - val_loss: 0.9097\n",
      "Epoch 469/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7589 - val_loss: 0.9061\n",
      "Epoch 470/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7571 - val_loss: 0.9092\n",
      "Epoch 471/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7565 - val_loss: 0.9130\n",
      "Epoch 472/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7575 - val_loss: 0.9130\n",
      "Epoch 473/500\n",
      "105/105 [==============================] - 0s 162us/sample - loss: 0.7573 - val_loss: 0.9138\n",
      "Epoch 474/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7563 - val_loss: 0.9105\n",
      "Epoch 475/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7563 - val_loss: 0.9115\n",
      "Epoch 476/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7561 - val_loss: 0.9078\n",
      "Epoch 477/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7565 - val_loss: 0.9078\n",
      "Epoch 478/500\n",
      "105/105 [==============================] - 0s 199us/sample - loss: 0.7559 - val_loss: 0.9049\n",
      "Epoch 479/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7569 - val_loss: 0.9017\n",
      "Epoch 480/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7559 - val_loss: 0.9029\n",
      "Epoch 481/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7558 - val_loss: 0.9015\n",
      "Epoch 482/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7565 - val_loss: 0.9052\n",
      "Epoch 483/500\n",
      "105/105 [==============================] - 0s 163us/sample - loss: 0.7555 - val_loss: 0.9063\n",
      "Epoch 484/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7563 - val_loss: 0.9071\n",
      "Epoch 485/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7570 - val_loss: 0.9069\n",
      "Epoch 486/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7566 - val_loss: 0.9054\n",
      "Epoch 487/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7565 - val_loss: 0.9045\n",
      "Epoch 488/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7566 - val_loss: 0.8997\n",
      "Epoch 489/500\n",
      "105/105 [==============================] - 0s 207us/sample - loss: 0.7562 - val_loss: 0.8983\n",
      "Epoch 490/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7557 - val_loss: 0.8987\n",
      "Epoch 491/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7566 - val_loss: 0.8984\n",
      "Epoch 492/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7568 - val_loss: 0.8996\n",
      "Epoch 493/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7563 - val_loss: 0.8995\n",
      "Epoch 494/500\n",
      "105/105 [==============================] - 0s 210us/sample - loss: 0.7565 - val_loss: 0.9000\n",
      "Epoch 495/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7567 - val_loss: 0.9035\n",
      "Epoch 496/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7557 - val_loss: 0.9060\n",
      "Epoch 497/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7565 - val_loss: 0.9058\n",
      "Epoch 498/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7560 - val_loss: 0.9049\n",
      "Epoch 499/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7563 - val_loss: 0.9018\n",
      "Epoch 500/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7568 - val_loss: 0.8988\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAbzklEQVR4nO3da3Cc1Z3n8e//6YskyxdhWQGCARFgAJmLMSoICxvABArChJoJzgwXJxmWKtemWCCbYWZMltpNnE0KeBFuw6TiSSCTwQOTjMOsh63gEELIMMziyMaYi3EMiRlEDJYVfMeSuvu/L/rpVutiWZb0qOXTv09Vl7uffvo550jtXx+d5/R5zN0REZHwRNWugIiIJEMBLyISKAW8iEigFPAiIoFSwIuIBCpd7QpUmjNnjre2tla7GiIih421a9dud/eW4Z6bUgHf2tpKR0dHtashInLYMLO3D/SchmhERAKlgBcRCZQCXkQkUFNqDF5Epp6+vj46OzvZv39/tatS0+rr65k7dy6ZTGbUr1HAi8iIOjs7mTFjBq2trZhZtatTk9yd7u5uOjs7OeGEE0b9Og3RiMiI9u/fT3Nzs8K9isyM5ubmQ/4rSgEvIgelcK++sfwOEgt4MzvFzNZX3HaZ2ZeSKOuBZzbz3K+7kji0iMhhK7GAd/dN7j7f3ecD5wD7gCeSKOvbv3iL5zcr4EVC1N3dzfz585k/fz5HHXUUxxxzTPlxb2/vqI5x4403smnTphH3eeihh1ixYsVEVJkLL7yQ9evXT8ixxmOyTrJeCrzl7gf8xtV4pCMjV9CFS0RC1NzcXA7Lr371q0yfPp3bb799wD7ujrsTRcP3WR955JGDlnPzzTePv7JTzGSNwV8LPDbcE2a2xMw6zKyjq2tsvfBUyigo4EVqyptvvklbWxs33HAD8+bNY+vWrSxZsoT29nbmzZvHsmXLyvuWetS5XI6mpiaWLl3KWWedxfnnn8+2bdsAuPPOO7nvvvvK+y9dupRzzz2XU045hRdeeAGAvXv3cs0119DW1saiRYtob28/aE/90Ucf5YwzzuD000/nK1/5CgC5XI7Pfe5z5e0PPPAAAPfeey9tbW2ceeaZLF68eNw/o8R78GaWBa4G7hjueXdfDiwHaG9vH1NKqwcvMjm+9i+v8frvdk3oMds+OpP/9el5Y3rtG2+8wQ9+8APa29sBuOuuu5g9eza5XI5LLrmERYsW0dbWNuA1O3fu5KKLLuKuu+7iy1/+Mg8//DBLly4dcmx3Z82aNaxatYply5bx1FNP8eCDD3LUUUexcuVKXn75ZRYsWDBi/To7O7nzzjvp6Ohg1qxZfPKTn+TJJ5+kpaWF7du388orrwCwY8cOAO655x7efvttstlsedt4TEYP/kpgnbu/n1QBqcjIK+BFas6JJ55YDneAxx57jAULFrBgwQI2btzI66+/PuQ1DQ0NXHnllQCcc845bNmyZdhjf+Yznxmyz/PPP8+1114LwFlnncW8eSN/ML344ossXLiQOXPmkMlkuP766/nlL3/JSSedxKZNm7j11ltZvXo1s2bNAmDevHksXryYFStWHNIXmg5kMsbgr+MAwzMTJR1F6sGLTIKx9rST0tjYWL6/efNm7r//ftasWUNTUxOLFy8edt54Npst30+lUuRyuWGPXVdXd9B9xqq5uZkNGzbwk5/8hIceeoiVK1eyfPlyVq9ezXPPPceqVav45je/yYYNG0ilUmMuJ9EevJk1ApcBP06yHPXgRWTXrl3MmDGDmTNnsnXrVlavXj3hZVxwwQX88Ic/BOCVV14Z9i+ESueddx7PPvss3d3d5HI5Hn/8cS666CK6urpwdz772c+ybNky1q1bRz6fp7Ozk4ULF3LPPfewfft29u3bN676JtqDd/e9QHOSZYDG4EUEFixYQFtbG6eeeirHH388F1xwwYSXccstt/D5z3+etra28q00vDKcuXPn8vWvf52LL74Yd+fTn/40V111FevWreOmm27C3TEz7r77bnK5HNdffz27d++mUChw++23M2PGjHHV19ynTjC2t7f7WC74cdm3nuPkI6fzNzeck0CtRGrbxo0bOe2006pdjSkhl8uRy+Wor69n8+bNXH755WzevJl0enJmnA/3uzCzte7ePtz+QSw2loqMXH7qfFCJSJj27NnDpZdeSi6Xw935zne+M2nhPhZTt2aHIJ3SGLyIJK+pqYm1a9dWuxqjFsRiYynNohFJ1FQayq1VY/kdBBHwac2iEUlMfX093d3dCvkqKq0HX19ff0ivC2KIJhUZuUKh2tUQCdLcuXPp7OxkrEuJyMQoXdHpUAQR8OnI6Msr4EWSkMlkDukqQjJ1BDFEk9I8eBGRIYIIeI3Bi4gMFUTAp6JI8+BFRAYJIuDVgxcRGSqIgE+lNItGRGSwIAJePXgRkaGCCHjNohERGSqIgFcPXkRkqCACXmvRiIgMFUTAqwcvIjJUEAFfXA9es2hERCoFEfDqwYuIDBVEwBfnwSvgRUQqBRHw6sGLiAwVRMCnrNiD1wUJRET6JRrwZtZkZv9kZm+Y2UYzOz+JclJRsRnqxIuI9Ev6gh/3A0+5+yIzywLTkigknTIAcoUCqSiVRBEiIoedxALezGYBnwD+DMDde4HeJMpKRcWA1zi8iEi/JIdoTgC6gEfM7CUz+66ZNSZRUDoq9eAV8CIiJUkGfBpYAHzb3c8G9gJLB+9kZkvMrMPMOsZ6Ud9SD76ggBcRKUsy4DuBTnd/MX78TxQDfwB3X+7u7e7e3tLSMqaC1IMXERkqsYB39/eAd8zslHjTpcDrSZRVmkWjMXgRkX5Jz6K5BVgRz6D5DXBjEoWoBy8iMlSiAe/u64H2JMuAilk0uvC2iEhZEN9kLc2D79N1WUVEysII+HgMPqcevIhIWRABn4r6v8kqIiJFQQR8prRUgXrwIiJlQQR8OhUP0agHLyJSFkTAZ+Ihmj714EVEyoII+HIPXgEvIlIWSMBrmqSIyGBBBHxG0yRFRIYIIuDLF/zIqwcvIlISRMBnykM06sGLiJQEEfD9q0mqBy8iUhJEwKc1TVJEZIggAj6jaZIiIkMEEfDlk6waohERKQsi4EvTJDVEIyLSL4iA1zRJEZGhwgp4TZMUESkLIuD7h2jUgxcRKQki4KPIiEyzaEREKgUR8FC8bJ+GaERE+oUT8CnTSVYRkQrhBHxk6sGLiFRIJ3lwM9sC7AbyQM7d25MqK5OKdJJVRKRCogEfu8TdtyddSHGIRj14EZGSgIZoIl3RSUSkQtIB78BPzWytmS0ZbgczW2JmHWbW0dXVNeaCMurBi4gMkHTAX+juC4ArgZvN7BODd3D35e7e7u7tLS0tYy4onYq02JiISIVEA97d343/3QY8AZybVFnpyLTYmIhIhcQC3swazWxG6T5wOfBqUuWlU0Ze0yRFRMqSnEVzJPCEmZXK+Qd3fyqpwtKRpkmKiFRKLODd/TfAWUkdfzCdZBURGSiYaZL6opOIyEBhBbzG4EVEysIK+Jx68CIiJcEEfDZt9GqIRkSkLJiA1xi8iMhAwQR8VkM0IiIDBBPwmXREr6ZJioiUBRPwWQ3RiIgMEE7ApyN6NUQjIlIWTMBnUqYevIhIhYACPiJXcAr6spOICBBYwAO6qpOISCyYgK9LF5uicXgRkaJgAr7cg9dUSRERIMiAVw9eRASCCngDNEQjIlISTMBn0+rBi4hUCifg4yEarSgpIlIUTMCXx+BzOskqIgIhBXxaPXgRkUqjCngzO9HM6uL7F5vZrWbWlGzVDk1Ws2hERAYYbQ9+JZA3s5OA5cCxwD8kVqsxyKY1i0ZEpNJoA77g7jngj4EH3f0vgKNH80IzS5nZS2b25FgrORqaBy8iMtBoA77PzK4DvgCUgjozytfeBmw81IodKgW8iMhAow34G4HzgW+4+2/N7ATg7w/2IjObC1wFfHfsVRydbPkkq2bRiIgApEezk7u/DtwKYGZHADPc/e5RvPQ+4C+BGQfawcyWAEsAjjvuuNFUZ1jlefAagxcRAUY/i+YXZjbTzGYD64C/NbNvHeQ1fwhsc/e1I+3n7svdvd3d21taWkZd8cG0mqSIyECjHaKZ5e67gM8AP3D384BPHuQ1FwBXm9kW4HFgoZk9OuaaHkRdOgVATy6fVBEiIoeV0QZ82syOBv6E/pOsI3L3O9x9rru3AtcCP3f3xWOr5sHVZYpN6VEPXkQEGH3ALwNWA2+5+6/M7GPA5uSqdehKY/A9fQp4EREY/UnWHwE/qnj8G+Ca0Rbi7r8AfnGIdTskUWRkUqYhGhGR2GhPss41syfMbFt8WxlPgZxS6tIpDdGIiMRGO0TzCLAK+Gh8+5d425RSl47UgxcRiY024Fvc/RF3z8W37wNjn9OYkLp0pDF4EZHYaAO+28wWx+vKpMxsMdCdZMXGoi6jIRoRkZLRBvx/oThF8j1gK7AI+LOE6jRmGqIREek3qoB397fd/Wp3b3H3j7j7H3EIs2gmSzYd6ZusIiKx8VzR6csTVosJUuzBK+BFRGB8AW8TVosJommSIiL9xhPwU25dXo3Bi4j0G/GbrGa2m+GD3ICGRGo0DnUZTZMUESkZMeDd/YDruE9FGqIREek3niGaKUdDNCIi/YIK+Kxm0YiIlAUV8FqqQESkX1ABX59JsT+Xx33KTfAREZl0wQW8O/Tm1YsXEQkq4BsyxeuyftirE60iImEFfDYO+D4FvIhIWAGvHryISFlYAa8evIhIWVgBrx68iEhZWAGvHryISFliAW9m9Wa2xsxeNrPXzOxrSZVVoh68iEi/ERcbG6ceYKG77zGzDPC8mf3E3f9fUgWqBy8i0i+xgPfi10n3xA8z8S3Rr5iqBy8i0i/RMXgzS5nZemAb8LS7v5hkeeWAVw9eRCTZgHf3vLvPB+YC55rZ6YP3MbMlZtZhZh1dXV3jKk9DNCIi/SZlFo277wCeBa4Y5rnl7t7u7u0tLS3jKqcuHWEG+zVEIyKS6CyaFjNriu83AJcBbyRVXlwODZkU+xTwIiKJzqI5Gvg7M0tR/CD5obs/mWB5QHEcfp+GaEREEp1FswE4O6njH8i0uhT7enKTXayIyJQT1DdZARqzafb0qAcvIhJcwE+vS7NXPXgRkQADvj7N3l4FvIhIcAHfWJdmj3rwIiLhBfz0bJo9+xXwIiLBBXyjxuBFRIAAA356XYq9vXkKhUTXNRMRmfKCC/jGuuLUfn3ZSURqXbABr2EaEal1wQX89DjgNZNGRGpduAGvmTQiUuOCC/iZDRkAdu3vq3JNRESqK7iAb5pWDPgd+xTwIlLbwgv4uAe/40MFvIjUtuACvjxEo4AXkRoXXMDXZ1LUZyJ27OutdlVERKoquIAHaGrIslM9eBGpcUEG/KyGjE6yikjNCzPgp2V0klVEal6QAd/UkNFJVhGpeUEGvIZoREQCDfimaRl2fKhZNCJS2wIN+Cz7+wrs15LBIlLDEgt4MzvWzJ41s9fN7DUzuy2psgbTl51ERJLtweeAP3f3NuDjwM1m1pZgeWWl5Qo0F15EalliAe/uW919XXx/N7AROCap8iqVFxxTwItIDZuUMXgzawXOBl4c5rklZtZhZh1dXV0TUt6sBq0oKSKSeMCb2XRgJfAld981+Hl3X+7u7e7e3tLSMiFlNjVkAQ3RiEhtSzTgzSxDMdxXuPuPkyyr0qzymvCaKikitSvJWTQGfA/Y6O7fSqqc4cysT5NJGd17FfAiUruS7MFfAHwOWGhm6+PbpxIsr8zMOGJalt/vUcCLSO1KJ3Vgd38esKSOfzCzG7PqwYtITQvym6wAzdOz/H5vT7WrISJSNcEG/BHTsvxePXgRqWHBBnyzhmhEpMYFG/CzG+vYvT9HT04LjolIbQo24D8ysw6A7ZpJIyI1KtiAP2pmPQDv79pf5ZqIiFRHsAFf6sFvU8CLSI0KNuCPLPfgNVVSRGpTsAE/e1qWdGQaohGRmhVswEeR8ZEZdby3UwEvIrUp2IAHOHb2NN75YF+1qyEiUhVBB3xrcyNbuhXwIlKbgg744+dMo2t3D3t7ctWuiojIpAs64FubGwHY0r23yjUREZl8QQf8iS3TAfj1+7urXBMRkckXeMA3UpeOeO3dIZeCFREJXtABn05FnHrUDF77nQJeRGpP0AEP0PbRWbz2u524e7WrIiIyqYIP+Hkfncmu/Tk6P/iw2lUREZlUNRHwgIZpRKTmBB/wpx41k3RkrH9nR7WrIiIyqYIP+IZsigXHH8Hzb3ZVuyoiIpMqsYA3s4fNbJuZvZpUGaP1iZPn8Oq7u9i+R0sHi0jtSLIH/33gigSPP2r/+eQWAP7tze1VromIyORJLODd/ZfA75M6/qE4/ZhZNE3L8NwmDdOISO2o+hi8mS0xsw4z6+jqSiaAU5Fx2WlH8tPX3+fD3nwiZYiITDVVD3h3X+7u7e7e3tLSklg5i86Zy56eHCtefDuxMkREppKqB/xkOfeE2Vx8Sgv3/WyzLuMnIjWhZgLezPja1fPoyxf47/+4nr58odpVEhFJVJLTJB8D/h04xcw6zeympMoareObG/nGH5/BC291843/u7Ha1RERSVQ6qQO7+3VJHXs8Fp0zlze27uK7z/+W/X15vnjxiRw3expmVu2qiYhMqMQCfipbeuWpRJHxved/y+O/eofmxixnH9fE2ccdwdnHNtE6p5GWGXVEZvTlC2RTEVGkDwARObzUZMCnUxFf+dRpXH/ucfzbW9t56T92sO4/PuBnG7cNu78ZzGrIkE1FA7aV72OYwWg/Akb714IZRGZEBg7kC06h4OztzZOOjCgy3Iv7ZVMR6ZQRjXDsvnyBHfv6mFGfxh1yBScyyKYjzKC0ovLglZXdHR9me2U9BzweQ3uHHCN+3JsrnitJR/11dHcKDoVyvYoVi8xIRcVbb65AZEZdJhrQJscP2M6D1elg+2aiuCxKxz9wAaWfibuTK/TXySy+VbynxvLXZel3VnCnUIA9PTnq0hEN2dSA389wNRzy+x9mr6HvEejJFcikbMD7cHD9c4VCuW0Fd3bvzzGjPk0u7+QLTiYVkUlZ+ffb/3/AyBUK9OWKP69MyqhLR5hZua2D65bLF+jNF6hLp4ii/uMY0JsvkMv3H7/y/1renQ97C9SlI1IjdOyG+7mM9DMaTjoqtrVpWoZV/+3Cg7/gENVkwJe0zmmkdU4jN5x3PAA79vXycudO3v3gQ7p292BWnEPfkyvwwd5ecoVi2FT+4twHhsbBjHZV+srj5gvFN2LKiqE+LZsqhn0c7u5OX97pyxdGrEdk0DQty56eXPlY7l4OUaCczhbfMevfXAqege0ZWODQcBi+bSMdA+9/XTZVDPZc/OFm8X/C0n9Ki/8tHteLQeFOJooouA84mW4VoTO4nUPqOFzNnQN+irsXP0AHlMHwHxKD218KxNKHV+lDa6QP1dHo/zkZ0+tS9OQK7OvNH/QDuVhvO+g+gzfWpVP05QvkCz6k/qVmpGzg44ZMqvzBEJnRG7++FMQQf0h5MQzTKSMVReTyBXpylb/bgdWxOMyz6YjeXCHuFPR3DEodouLxoVDo/0A0oCGbpieXP3gnYOSnR96hopPVNC17sCONSU0H/GBN07Jc9AfJzcUXEZlMNTNNUkSk1ijgRUQCpYAXEQmUAl5EJFAKeBGRQCngRUQCpYAXEQmUAl5EJFA20tepJ5uZdQFjuSLHHKDWLriqNtcGtbk2jKfNx7v7sN/QnFIBP1Zm1uHu7dWux2RSm2uD2lwbkmqzhmhERAKlgBcRCVQoAb+82hWoArW5NqjNtSGRNgcxBi8iIkOF0oMXEZFBFPAiIoE67APezK4ws01m9qaZLa12fSaKmT1sZtvM7NWKbbPN7Gkz2xz/e0S83czsgfhnsMHMFlSv5mNjZsea2bNm9rqZvWZmt8Xbg20zgJnVm9kaM3s5bvfX4u0nmNmLcfv+0cyy8fa6+PGb8fOt1az/WJlZysxeMrMn48dBtxfAzLaY2Stmtt7MOuJtib6/D+uAN7MU8BBwJdAGXGdmbdWt1YT5PnDFoG1LgWfc/WTgmfgxFNt/cnxbAnx7kuo4kXLAn7t7G/Bx4Ob4dxlymwF6gIXufhYwH7jCzD4O3A3c6+4nAR8AN8X73wR8EG+/N97vcHQbsLHicejtLbnE3edXzHlP9v3t7oftDTgfWF3x+A7gjmrXawLb1wq8WvF4E3B0fP9oYFN8/zvAdcPtd7jegP8DXFZjbZ4GrAPOo/itxnS8vfw+B1YD58f30/F+Vu26H2I758ZhthB4kuKVS4Ntb0W7twBzBm1L9P19WPfggWOAdyoed8bbQnWku2+N778HHBnfD+rnEP8ZfjbwIjXQ5ni4Yj2wDXgaeAvY4e65eJfKtpXbHT+/E2ie3BqP233AXwKlq2Y3E3Z7Sxz4qZmtNbMl8bZE39+66PZhyt3dzIKb42pm04GVwJfcfZdZ/2XpQ22zu+eB+WbWBDwBnFrlKiXGzP4Q2Obua83s4mrXZ5Jd6O7vmtlHgKfN7I3KJ5N4fx/uPfh3gWMrHs+Nt4XqfTM7GiD+d1u8PYifg5llKIb7Cnf/cbw56DZXcvcdwLMUhyiazKzUAatsW7nd8fOzgO5Jrup4XABcbWZbgMcpDtPcT7jtLXP3d+N/t1H8ID+XhN/fh3vA/wo4OT4DnwWuBVZVuU5JWgV8Ib7/BYrj1KXtn4/PvH8c2FnxZ99hwYpd9e8BG939WxVPBdtmADNriXvumFkDxfMOGykG/aJ4t8HtLv08FgE/93iQ9nDg7ne4+1x3b6X4//Xn7n4Dgba3xMwazWxG6T5wOfAqSb+/q33iYQJOXHwK+DXFccv/Ue36TGC7HgO2An0Ux99uojj2+AywGfgZMDve1yjOJnoLeAVor3b9x9DeCymOUW4A1se3T4Xc5rgdZwIvxe1+Ffif8faPAWuAN4EfAXXx9vr48Zvx8x+rdhvG0faLgSdrob1x+16Ob6+Vsirp97eWKhARCdThPkQjIiIHoIAXEQmUAl5EJFAKeBGRQCngRUQCpYCX4JlZPl7Br3SbsFVHzazVKlb8FJlKtFSB1IIP3X1+tSshMtnUg5eaFa/PfU+8RvcaMzsp3t5qZj+P1+F+xsyOi7cfaWZPxGu3v2xm/yk+VMrM/jZez/2n8TdSMbNbrbi+/QYze7xKzZQapoCXWtAwaIjmTyue2+nuZwB/TXGVQ4AHgb9z9zOBFcAD8fYHgOe8uHb7AorfSITimt0Pufs8YAdwTbx9KXB2fJz/mlTjRA5E32SV4JnZHnefPsz2LRQvtvGbeKGz99y92cy2U1x7uy/evtXd55hZFzDX3XsqjtEKPO3FCzZgZn8FZNz9f5vZU8Ae4J+Bf3b3PQk3VWQA9eCl1vkB7h+Knor7efrPbV1FcT2RBcCvKlZLFJkUCnipdX9a8e+/x/dfoLjSIcANwL/G958Bvgjli3TMOtBBzSwCjnX3Z4G/orjM7ZC/IkSSpB6F1IKG+IpJJU+5e2mq5BFmtoFiL/y6eNstwCNm9hdAF3BjvP02YLmZ3USxp/5Fiit+DicFPBp/CBjwgBfXexeZNBqDl5oVj8G3u/v2atdFJAkaohERCZR68CIigVIPXkQkUAp4EZFAKeBFRAKlgBcRCZQCXkQkUP8f1xLZ1VHtqGQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, 500+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "input = Input(shape=(1,))\n",
    "output = Dense(1)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dese = Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dese(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 7.3995 - val_loss: 4.4674\n",
      "Epoch 2/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 6.1388 - val_loss: 3.7706\n",
      "Epoch 3/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 5.0736 - val_loss: 3.2346\n",
      "Epoch 4/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 4.2457 - val_loss: 2.7425\n",
      "Epoch 5/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 3.4994 - val_loss: 2.3831\n",
      "Epoch 6/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 2.9654 - val_loss: 2.1024\n",
      "Epoch 7/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 2.5457 - val_loss: 1.8884\n",
      "Epoch 8/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 2.2089 - val_loss: 1.7117\n",
      "Epoch 9/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 1.9373 - val_loss: 1.5643\n",
      "Epoch 10/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 1.7109 - val_loss: 1.4297\n",
      "Epoch 11/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 1.5037 - val_loss: 1.3238\n",
      "Epoch 12/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 1.3490 - val_loss: 1.2544\n",
      "Epoch 13/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 1.2482 - val_loss: 1.1947\n",
      "Epoch 14/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 1.1548 - val_loss: 1.1346\n",
      "Epoch 15/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 1.0692 - val_loss: 1.0871\n",
      "Epoch 16/500\n",
      "105/105 [==============================] - 0s 191us/sample - loss: 1.0103 - val_loss: 1.0557\n",
      "Epoch 17/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.9665 - val_loss: 1.0246\n",
      "Epoch 18/500\n",
      "105/105 [==============================] - 0s 191us/sample - loss: 0.9235 - val_loss: 1.0082\n",
      "Epoch 19/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.8980 - val_loss: 0.9905\n",
      "Epoch 20/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.8745 - val_loss: 0.9658\n",
      "Epoch 21/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.8515 - val_loss: 0.9577\n",
      "Epoch 22/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.8368 - val_loss: 0.9442\n",
      "Epoch 23/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.8209 - val_loss: 0.9362\n",
      "Epoch 24/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.8065 - val_loss: 0.9303\n",
      "Epoch 25/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7996 - val_loss: 0.9289\n",
      "Epoch 26/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7930 - val_loss: 0.9247\n",
      "Epoch 27/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7838 - val_loss: 0.9214\n",
      "Epoch 28/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7791 - val_loss: 0.9203\n",
      "Epoch 29/500\n",
      "105/105 [==============================] - 0s 191us/sample - loss: 0.7758 - val_loss: 0.9168\n",
      "Epoch 30/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7708 - val_loss: 0.9097\n",
      "Epoch 31/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7668 - val_loss: 0.9093\n",
      "Epoch 32/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7660 - val_loss: 0.9108\n",
      "Epoch 33/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7660 - val_loss: 0.9081\n",
      "Epoch 34/500\n",
      "105/105 [==============================] - 0s 210us/sample - loss: 0.7639 - val_loss: 0.9107\n",
      "Epoch 35/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7648 - val_loss: 0.9128\n",
      "Epoch 36/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7643 - val_loss: 0.9114\n",
      "Epoch 37/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7625 - val_loss: 0.9111\n",
      "Epoch 38/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7622 - val_loss: 0.9149\n",
      "Epoch 39/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7606 - val_loss: 0.9144\n",
      "Epoch 40/500\n",
      "105/105 [==============================] - 0s 169us/sample - loss: 0.7600 - val_loss: 0.9156\n",
      "Epoch 41/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7591 - val_loss: 0.9161\n",
      "Epoch 42/500\n",
      "105/105 [==============================] - 0s 169us/sample - loss: 0.7610 - val_loss: 0.9156\n",
      "Epoch 43/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7577 - val_loss: 0.9137\n",
      "Epoch 44/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7582 - val_loss: 0.9098\n",
      "Epoch 45/500\n",
      "105/105 [==============================] - 0s 203us/sample - loss: 0.7569 - val_loss: 0.9093\n",
      "Epoch 46/500\n",
      "105/105 [==============================] - 0s 201us/sample - loss: 0.7567 - val_loss: 0.9065\n",
      "Epoch 47/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7582 - val_loss: 0.9082\n",
      "Epoch 48/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7568 - val_loss: 0.9071\n",
      "Epoch 49/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7572 - val_loss: 0.9090\n",
      "Epoch 50/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7570 - val_loss: 0.9063\n",
      "Epoch 51/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7575 - val_loss: 0.9044\n",
      "Epoch 52/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7563 - val_loss: 0.9065\n",
      "Epoch 53/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7578 - val_loss: 0.9077\n",
      "Epoch 54/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7575 - val_loss: 0.9147\n",
      "Epoch 55/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7572 - val_loss: 0.9134\n",
      "Epoch 56/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7560 - val_loss: 0.9122\n",
      "Epoch 57/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7569 - val_loss: 0.9117\n",
      "Epoch 58/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7570 - val_loss: 0.9125\n",
      "Epoch 59/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7563 - val_loss: 0.9083\n",
      "Epoch 60/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7568 - val_loss: 0.9171\n",
      "Epoch 61/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7576 - val_loss: 0.9189\n",
      "Epoch 62/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7579 - val_loss: 0.9151\n",
      "Epoch 63/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7567 - val_loss: 0.9103\n",
      "Epoch 64/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7566 - val_loss: 0.9074\n",
      "Epoch 65/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7562 - val_loss: 0.9064\n",
      "Epoch 66/500\n",
      "105/105 [==============================] - 0s 201us/sample - loss: 0.7572 - val_loss: 0.9027\n",
      "Epoch 67/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7564 - val_loss: 0.9039\n",
      "Epoch 68/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7561 - val_loss: 0.9046\n",
      "Epoch 69/500\n",
      "105/105 [==============================] - 0s 201us/sample - loss: 0.7588 - val_loss: 0.9043\n",
      "Epoch 70/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7568 - val_loss: 0.9070\n",
      "Epoch 71/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7571 - val_loss: 0.9110\n",
      "Epoch 72/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7569 - val_loss: 0.9125\n",
      "Epoch 73/500\n",
      "105/105 [==============================] - 0s 161us/sample - loss: 0.7565 - val_loss: 0.9162\n",
      "Epoch 74/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7568 - val_loss: 0.9169\n",
      "Epoch 75/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7574 - val_loss: 0.9145\n",
      "Epoch 76/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7575 - val_loss: 0.9139\n",
      "Epoch 77/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7565 - val_loss: 0.9156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7562 - val_loss: 0.9175\n",
      "Epoch 79/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7571 - val_loss: 0.9102\n",
      "Epoch 80/500\n",
      "105/105 [==============================] - 0s 184us/sample - loss: 0.7568 - val_loss: 0.9118\n",
      "Epoch 81/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7579 - val_loss: 0.9117\n",
      "Epoch 82/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7575 - val_loss: 0.9103\n",
      "Epoch 83/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7560 - val_loss: 0.9079\n",
      "Epoch 84/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7590 - val_loss: 0.9083\n",
      "Epoch 85/500\n",
      "105/105 [==============================] - 0s 155us/sample - loss: 0.7563 - val_loss: 0.9077\n",
      "Epoch 86/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7571 - val_loss: 0.9082\n",
      "Epoch 87/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7566 - val_loss: 0.9070\n",
      "Epoch 88/500\n",
      "105/105 [==============================] - 0s 162us/sample - loss: 0.7568 - val_loss: 0.9049\n",
      "Epoch 89/500\n",
      "105/105 [==============================] - 0s 165us/sample - loss: 0.7575 - val_loss: 0.9027\n",
      "Epoch 90/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7562 - val_loss: 0.9070\n",
      "Epoch 91/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7568 - val_loss: 0.9049\n",
      "Epoch 92/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7563 - val_loss: 0.9046\n",
      "Epoch 93/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7563 - val_loss: 0.9032\n",
      "Epoch 94/500\n",
      "105/105 [==============================] - 0s 165us/sample - loss: 0.7562 - val_loss: 0.9024\n",
      "Epoch 95/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7567 - val_loss: 0.9009\n",
      "Epoch 96/500\n",
      "105/105 [==============================] - 0s 165us/sample - loss: 0.7563 - val_loss: 0.9021\n",
      "Epoch 97/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7559 - val_loss: 0.9022\n",
      "Epoch 98/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7566 - val_loss: 0.9036\n",
      "Epoch 99/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7558 - val_loss: 0.9041\n",
      "Epoch 100/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7560 - val_loss: 0.9030\n",
      "Epoch 101/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7556 - val_loss: 0.9028\n",
      "Epoch 102/500\n",
      "105/105 [==============================] - 0s 170us/sample - loss: 0.7558 - val_loss: 0.9031\n",
      "Epoch 103/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7564 - val_loss: 0.9000\n",
      "Epoch 104/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7562 - val_loss: 0.8996\n",
      "Epoch 105/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7563 - val_loss: 0.8999\n",
      "Epoch 106/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7582 - val_loss: 0.9063\n",
      "Epoch 107/500\n",
      "105/105 [==============================] - 0s 169us/sample - loss: 0.7564 - val_loss: 0.9022\n",
      "Epoch 108/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7562 - val_loss: 0.9055\n",
      "Epoch 109/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7574 - val_loss: 0.9023\n",
      "Epoch 110/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7568 - val_loss: 0.9036\n",
      "Epoch 111/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7573 - val_loss: 0.9080\n",
      "Epoch 112/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7559 - val_loss: 0.9061\n",
      "Epoch 113/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7559 - val_loss: 0.9047\n",
      "Epoch 114/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7559 - val_loss: 0.9065\n",
      "Epoch 115/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7568 - val_loss: 0.9052\n",
      "Epoch 116/500\n",
      "105/105 [==============================] - 0s 169us/sample - loss: 0.7561 - val_loss: 0.9060\n",
      "Epoch 117/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7572 - val_loss: 0.9081\n",
      "Epoch 118/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7562 - val_loss: 0.9093\n",
      "Epoch 119/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7567 - val_loss: 0.9074\n",
      "Epoch 120/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7572 - val_loss: 0.9061\n",
      "Epoch 121/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7567 - val_loss: 0.9058\n",
      "Epoch 122/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7558 - val_loss: 0.9024\n",
      "Epoch 123/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7561 - val_loss: 0.9072\n",
      "Epoch 124/500\n",
      "105/105 [==============================] - 0s 203us/sample - loss: 0.7569 - val_loss: 0.9087\n",
      "Epoch 125/500\n",
      "105/105 [==============================] - 0s 275us/sample - loss: 0.7563 - val_loss: 0.9083\n",
      "Epoch 126/500\n",
      "105/105 [==============================] - 0s 312us/sample - loss: 0.7560 - val_loss: 0.9043\n",
      "Epoch 127/500\n",
      "105/105 [==============================] - 0s 300us/sample - loss: 0.7575 - val_loss: 0.9059\n",
      "Epoch 128/500\n",
      "105/105 [==============================] - 0s 319us/sample - loss: 0.7565 - val_loss: 0.9092\n",
      "Epoch 129/500\n",
      "105/105 [==============================] - 0s 277us/sample - loss: 0.7563 - val_loss: 0.9106\n",
      "Epoch 130/500\n",
      "105/105 [==============================] - 0s 263us/sample - loss: 0.7563 - val_loss: 0.9084\n",
      "Epoch 131/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7569 - val_loss: 0.9090\n",
      "Epoch 132/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7566 - val_loss: 0.9054\n",
      "Epoch 133/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7558 - val_loss: 0.9044\n",
      "Epoch 134/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7561 - val_loss: 0.9021\n",
      "Epoch 135/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7577 - val_loss: 0.9021\n",
      "Epoch 136/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7571 - val_loss: 0.9015\n",
      "Epoch 137/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7570 - val_loss: 0.9018\n",
      "Epoch 138/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7555 - val_loss: 0.9024\n",
      "Epoch 139/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7565 - val_loss: 0.9019\n",
      "Epoch 140/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7566 - val_loss: 0.9043\n",
      "Epoch 141/500\n",
      "105/105 [==============================] - 0s 209us/sample - loss: 0.7566 - val_loss: 0.9087\n",
      "Epoch 142/500\n",
      "105/105 [==============================] - 0s 229us/sample - loss: 0.7559 - val_loss: 0.9085\n",
      "Epoch 143/500\n",
      "105/105 [==============================] - 0s 264us/sample - loss: 0.7565 - val_loss: 0.9131\n",
      "Epoch 144/500\n",
      "105/105 [==============================] - 0s 298us/sample - loss: 0.7567 - val_loss: 0.9168\n",
      "Epoch 145/500\n",
      "105/105 [==============================] - 0s 266us/sample - loss: 0.7572 - val_loss: 0.9165\n",
      "Epoch 146/500\n",
      "105/105 [==============================] - 0s 326us/sample - loss: 0.7581 - val_loss: 0.9151\n",
      "Epoch 147/500\n",
      "105/105 [==============================] - 0s 356us/sample - loss: 0.7571 - val_loss: 0.9126\n",
      "Epoch 148/500\n",
      "105/105 [==============================] - 0s 237us/sample - loss: 0.7583 - val_loss: 0.9172\n",
      "Epoch 149/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7578 - val_loss: 0.9161\n",
      "Epoch 150/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7572 - val_loss: 0.9112\n",
      "Epoch 151/500\n",
      "105/105 [==============================] - 0s 203us/sample - loss: 0.7562 - val_loss: 0.9124\n",
      "Epoch 152/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7563 - val_loss: 0.9105\n",
      "Epoch 153/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7569 - val_loss: 0.9096\n",
      "Epoch 154/500\n",
      "105/105 [==============================] - 0s 211us/sample - loss: 0.7558 - val_loss: 0.9076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7560 - val_loss: 0.9067\n",
      "Epoch 156/500\n",
      "105/105 [==============================] - 0s 165us/sample - loss: 0.7564 - val_loss: 0.9016\n",
      "Epoch 157/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7559 - val_loss: 0.9009\n",
      "Epoch 158/500\n",
      "105/105 [==============================] - 0s 163us/sample - loss: 0.7571 - val_loss: 0.9008\n",
      "Epoch 159/500\n",
      "105/105 [==============================] - 0s 163us/sample - loss: 0.7560 - val_loss: 0.8997\n",
      "Epoch 160/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7566 - val_loss: 0.9056\n",
      "Epoch 161/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7565 - val_loss: 0.9042\n",
      "Epoch 162/500\n",
      "105/105 [==============================] - 0s 163us/sample - loss: 0.7561 - val_loss: 0.9015\n",
      "Epoch 163/500\n",
      "105/105 [==============================] - 0s 165us/sample - loss: 0.7567 - val_loss: 0.9028\n",
      "Epoch 164/500\n",
      "105/105 [==============================] - 0s 162us/sample - loss: 0.7561 - val_loss: 0.8996\n",
      "Epoch 165/500\n",
      "105/105 [==============================] - 0s 160us/sample - loss: 0.7564 - val_loss: 0.9035\n",
      "Epoch 166/500\n",
      "105/105 [==============================] - 0s 166us/sample - loss: 0.7566 - val_loss: 0.9006\n",
      "Epoch 167/500\n",
      "105/105 [==============================] - 0s 160us/sample - loss: 0.7575 - val_loss: 0.8972\n",
      "Epoch 168/500\n",
      "105/105 [==============================] - 0s 164us/sample - loss: 0.7571 - val_loss: 0.8988\n",
      "Epoch 169/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7566 - val_loss: 0.8962\n",
      "Epoch 170/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7580 - val_loss: 0.8946\n",
      "Epoch 171/500\n",
      "105/105 [==============================] - 0s 177us/sample - loss: 0.7602 - val_loss: 0.8968\n",
      "Epoch 172/500\n",
      "105/105 [==============================] - 0s 207us/sample - loss: 0.7577 - val_loss: 0.8983\n",
      "Epoch 173/500\n",
      "105/105 [==============================] - 0s 282us/sample - loss: 0.7581 - val_loss: 0.8948\n",
      "Epoch 174/500\n",
      "105/105 [==============================] - 0s 303us/sample - loss: 0.7576 - val_loss: 0.9001\n",
      "Epoch 175/500\n",
      "105/105 [==============================] - 0s 226us/sample - loss: 0.7567 - val_loss: 0.8973\n",
      "Epoch 176/500\n",
      "105/105 [==============================] - 0s 232us/sample - loss: 0.7576 - val_loss: 0.8960\n",
      "Epoch 177/500\n",
      "105/105 [==============================] - 0s 231us/sample - loss: 0.7568 - val_loss: 0.8985\n",
      "Epoch 178/500\n",
      "105/105 [==============================] - 0s 243us/sample - loss: 0.7568 - val_loss: 0.8958\n",
      "Epoch 179/500\n",
      "105/105 [==============================] - 0s 208us/sample - loss: 0.7564 - val_loss: 0.9000\n",
      "Epoch 180/500\n",
      "105/105 [==============================] - 0s 274us/sample - loss: 0.7566 - val_loss: 0.9016\n",
      "Epoch 181/500\n",
      "105/105 [==============================] - 0s 293us/sample - loss: 0.7569 - val_loss: 0.8986\n",
      "Epoch 182/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7565 - val_loss: 0.8985\n",
      "Epoch 183/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7571 - val_loss: 0.8973\n",
      "Epoch 184/500\n",
      "105/105 [==============================] - 0s 174us/sample - loss: 0.7561 - val_loss: 0.8972\n",
      "Epoch 185/500\n",
      "105/105 [==============================] - 0s 268us/sample - loss: 0.7571 - val_loss: 0.8960\n",
      "Epoch 186/500\n",
      "105/105 [==============================] - 0s 288us/sample - loss: 0.7563 - val_loss: 0.8966\n",
      "Epoch 187/500\n",
      "105/105 [==============================] - 0s 290us/sample - loss: 0.7575 - val_loss: 0.8975\n",
      "Epoch 188/500\n",
      "105/105 [==============================] - 0s 252us/sample - loss: 0.7567 - val_loss: 0.8980\n",
      "Epoch 189/500\n",
      "105/105 [==============================] - 0s 265us/sample - loss: 0.7569 - val_loss: 0.8968\n",
      "Epoch 190/500\n",
      "105/105 [==============================] - 0s 256us/sample - loss: 0.7565 - val_loss: 0.8976\n",
      "Epoch 191/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7558 - val_loss: 0.8982\n",
      "Epoch 192/500\n",
      "105/105 [==============================] - 0s 274us/sample - loss: 0.7561 - val_loss: 0.9003\n",
      "Epoch 193/500\n",
      "105/105 [==============================] - 0s 266us/sample - loss: 0.7564 - val_loss: 0.8983\n",
      "Epoch 194/500\n",
      "105/105 [==============================] - 0s 279us/sample - loss: 0.7557 - val_loss: 0.8993\n",
      "Epoch 195/500\n",
      "105/105 [==============================] - 0s 253us/sample - loss: 0.7570 - val_loss: 0.9006\n",
      "Epoch 196/500\n",
      "105/105 [==============================] - 0s 262us/sample - loss: 0.7568 - val_loss: 0.8991\n",
      "Epoch 197/500\n",
      "105/105 [==============================] - 0s 295us/sample - loss: 0.7562 - val_loss: 0.8997\n",
      "Epoch 198/500\n",
      "105/105 [==============================] - 0s 236us/sample - loss: 0.7566 - val_loss: 0.8995\n",
      "Epoch 199/500\n",
      "105/105 [==============================] - 0s 222us/sample - loss: 0.7563 - val_loss: 0.8982\n",
      "Epoch 200/500\n",
      "105/105 [==============================] - 0s 309us/sample - loss: 0.7570 - val_loss: 0.9045\n",
      "Epoch 201/500\n",
      "105/105 [==============================] - 0s 309us/sample - loss: 0.7561 - val_loss: 0.9036\n",
      "Epoch 202/500\n",
      "105/105 [==============================] - 0s 260us/sample - loss: 0.7574 - val_loss: 0.9041\n",
      "Epoch 203/500\n",
      "105/105 [==============================] - 0s 253us/sample - loss: 0.7558 - val_loss: 0.9033\n",
      "Epoch 204/500\n",
      "105/105 [==============================] - 0s 266us/sample - loss: 0.7563 - val_loss: 0.9000\n",
      "Epoch 205/500\n",
      "105/105 [==============================] - 0s 251us/sample - loss: 0.7568 - val_loss: 0.9003\n",
      "Epoch 206/500\n",
      "105/105 [==============================] - 0s 223us/sample - loss: 0.7568 - val_loss: 0.8956\n",
      "Epoch 207/500\n",
      "105/105 [==============================] - 0s 281us/sample - loss: 0.7571 - val_loss: 0.8936\n",
      "Epoch 208/500\n",
      "105/105 [==============================] - 0s 266us/sample - loss: 0.7580 - val_loss: 0.8913\n",
      "Epoch 209/500\n",
      "105/105 [==============================] - 0s 226us/sample - loss: 0.7578 - val_loss: 0.8952\n",
      "Epoch 210/500\n",
      "105/105 [==============================] - 0s 214us/sample - loss: 0.7568 - val_loss: 0.8981\n",
      "Epoch 211/500\n",
      "105/105 [==============================] - 0s 244us/sample - loss: 0.7588 - val_loss: 0.8988\n",
      "Epoch 212/500\n",
      "105/105 [==============================] - 0s 242us/sample - loss: 0.7574 - val_loss: 0.8982\n",
      "Epoch 213/500\n",
      "105/105 [==============================] - 0s 290us/sample - loss: 0.7570 - val_loss: 0.8983\n",
      "Epoch 214/500\n",
      "105/105 [==============================] - 0s 209us/sample - loss: 0.7578 - val_loss: 0.8972\n",
      "Epoch 215/500\n",
      "105/105 [==============================] - 0s 254us/sample - loss: 0.7573 - val_loss: 0.8982\n",
      "Epoch 216/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7582 - val_loss: 0.8973\n",
      "Epoch 217/500\n",
      "105/105 [==============================] - 0s 219us/sample - loss: 0.7567 - val_loss: 0.9006\n",
      "Epoch 218/500\n",
      "105/105 [==============================] - 0s 240us/sample - loss: 0.7573 - val_loss: 0.9064\n",
      "Epoch 219/500\n",
      "105/105 [==============================] - 0s 287us/sample - loss: 0.7564 - val_loss: 0.9066\n",
      "Epoch 220/500\n",
      "105/105 [==============================] - 0s 407us/sample - loss: 0.7560 - val_loss: 0.9091\n",
      "Epoch 221/500\n",
      "105/105 [==============================] - 0s 639us/sample - loss: 0.7563 - val_loss: 0.9106\n",
      "Epoch 222/500\n",
      "105/105 [==============================] - 0s 557us/sample - loss: 0.7568 - val_loss: 0.9098\n",
      "Epoch 223/500\n",
      "105/105 [==============================] - 0s 465us/sample - loss: 0.7563 - val_loss: 0.9103\n",
      "Epoch 224/500\n",
      "105/105 [==============================] - 0s 348us/sample - loss: 0.7561 - val_loss: 0.9105\n",
      "Epoch 225/500\n",
      "105/105 [==============================] - 0s 290us/sample - loss: 0.7574 - val_loss: 0.9103\n",
      "Epoch 226/500\n",
      "105/105 [==============================] - 0s 215us/sample - loss: 0.7577 - val_loss: 0.9083\n",
      "Epoch 227/500\n",
      "105/105 [==============================] - 0s 227us/sample - loss: 0.7561 - val_loss: 0.9075\n",
      "Epoch 228/500\n",
      "105/105 [==============================] - 0s 203us/sample - loss: 0.7560 - val_loss: 0.9075\n",
      "Epoch 229/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7567 - val_loss: 0.9042\n",
      "Epoch 230/500\n",
      "105/105 [==============================] - 0s 300us/sample - loss: 0.7586 - val_loss: 0.9084\n",
      "Epoch 231/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 301us/sample - loss: 0.7560 - val_loss: 0.9113\n",
      "Epoch 232/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7562 - val_loss: 0.9080\n",
      "Epoch 233/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7567 - val_loss: 0.9064\n",
      "Epoch 234/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7565 - val_loss: 0.9060\n",
      "Epoch 235/500\n",
      "105/105 [==============================] - 0s 309us/sample - loss: 0.7568 - val_loss: 0.9049\n",
      "Epoch 236/500\n",
      "105/105 [==============================] - 0s 303us/sample - loss: 0.7562 - val_loss: 0.9053\n",
      "Epoch 237/500\n",
      "105/105 [==============================] - 0s 318us/sample - loss: 0.7564 - val_loss: 0.9037\n",
      "Epoch 238/500\n",
      "105/105 [==============================] - 0s 298us/sample - loss: 0.7561 - val_loss: 0.9027\n",
      "Epoch 239/500\n",
      "105/105 [==============================] - 0s 240us/sample - loss: 0.7566 - val_loss: 0.8987\n",
      "Epoch 240/500\n",
      "105/105 [==============================] - 0s 222us/sample - loss: 0.7567 - val_loss: 0.9007\n",
      "Epoch 241/500\n",
      "105/105 [==============================] - 0s 247us/sample - loss: 0.7564 - val_loss: 0.9000\n",
      "Epoch 242/500\n",
      "105/105 [==============================] - 0s 228us/sample - loss: 0.7562 - val_loss: 0.9006\n",
      "Epoch 243/500\n",
      "105/105 [==============================] - 0s 228us/sample - loss: 0.7566 - val_loss: 0.8995\n",
      "Epoch 244/500\n",
      "105/105 [==============================] - 0s 255us/sample - loss: 0.7570 - val_loss: 0.9002\n",
      "Epoch 245/500\n",
      "105/105 [==============================] - 0s 251us/sample - loss: 0.7573 - val_loss: 0.8996\n",
      "Epoch 246/500\n",
      "105/105 [==============================] - 0s 249us/sample - loss: 0.7568 - val_loss: 0.8999\n",
      "Epoch 247/500\n",
      "105/105 [==============================] - 0s 257us/sample - loss: 0.7564 - val_loss: 0.9006\n",
      "Epoch 248/500\n",
      "105/105 [==============================] - 0s 225us/sample - loss: 0.7564 - val_loss: 0.9002\n",
      "Epoch 249/500\n",
      "105/105 [==============================] - 0s 238us/sample - loss: 0.7564 - val_loss: 0.8988\n",
      "Epoch 250/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7576 - val_loss: 0.8958\n",
      "Epoch 251/500\n",
      "105/105 [==============================] - 0s 228us/sample - loss: 0.7588 - val_loss: 0.8970\n",
      "Epoch 252/500\n",
      "105/105 [==============================] - 0s 217us/sample - loss: 0.7568 - val_loss: 0.8971\n",
      "Epoch 253/500\n",
      "105/105 [==============================] - 0s 208us/sample - loss: 0.7569 - val_loss: 0.8973\n",
      "Epoch 254/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7561 - val_loss: 0.8968\n",
      "Epoch 255/500\n",
      "105/105 [==============================] - 0s 237us/sample - loss: 0.7565 - val_loss: 0.8976\n",
      "Epoch 256/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7567 - val_loss: 0.9038\n",
      "Epoch 257/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7561 - val_loss: 0.9008\n",
      "Epoch 258/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7575 - val_loss: 0.8972\n",
      "Epoch 259/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7566 - val_loss: 0.8995\n",
      "Epoch 260/500\n",
      "105/105 [==============================] - 0s 203us/sample - loss: 0.7556 - val_loss: 0.8995\n",
      "Epoch 261/500\n",
      "105/105 [==============================] - 0s 199us/sample - loss: 0.7563 - val_loss: 0.8999\n",
      "Epoch 262/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7561 - val_loss: 0.8994\n",
      "Epoch 263/500\n",
      "105/105 [==============================] - 0s 221us/sample - loss: 0.7566 - val_loss: 0.9011\n",
      "Epoch 264/500\n",
      "105/105 [==============================] - 0s 214us/sample - loss: 0.7561 - val_loss: 0.9004\n",
      "Epoch 265/500\n",
      "105/105 [==============================] - 0s 219us/sample - loss: 0.7560 - val_loss: 0.8979\n",
      "Epoch 266/500\n",
      "105/105 [==============================] - 0s 212us/sample - loss: 0.7569 - val_loss: 0.8974\n",
      "Epoch 267/500\n",
      "105/105 [==============================] - 0s 171us/sample - loss: 0.7564 - val_loss: 0.8961\n",
      "Epoch 268/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7561 - val_loss: 0.8954\n",
      "Epoch 269/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7569 - val_loss: 0.8931\n",
      "Epoch 270/500\n",
      "105/105 [==============================] - 0s 212us/sample - loss: 0.7566 - val_loss: 0.8930\n",
      "Epoch 271/500\n",
      "105/105 [==============================] - 0s 210us/sample - loss: 0.7569 - val_loss: 0.8925\n",
      "Epoch 272/500\n",
      "105/105 [==============================] - 0s 214us/sample - loss: 0.7584 - val_loss: 0.8923\n",
      "Epoch 273/500\n",
      "105/105 [==============================] - 0s 212us/sample - loss: 0.7573 - val_loss: 0.8932\n",
      "Epoch 274/500\n",
      "105/105 [==============================] - 0s 222us/sample - loss: 0.7567 - val_loss: 0.8959\n",
      "Epoch 275/500\n",
      "105/105 [==============================] - 0s 218us/sample - loss: 0.7569 - val_loss: 0.8957\n",
      "Epoch 276/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7560 - val_loss: 0.8946\n",
      "Epoch 277/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7566 - val_loss: 0.8969\n",
      "Epoch 278/500\n",
      "105/105 [==============================] - 0s 191us/sample - loss: 0.7562 - val_loss: 0.8949\n",
      "Epoch 279/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7577 - val_loss: 0.8959\n",
      "Epoch 280/500\n",
      "105/105 [==============================] - 0s 206us/sample - loss: 0.7572 - val_loss: 0.8979\n",
      "Epoch 281/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7565 - val_loss: 0.8999\n",
      "Epoch 282/500\n",
      "105/105 [==============================] - 0s 209us/sample - loss: 0.7567 - val_loss: 0.8980\n",
      "Epoch 283/500\n",
      "105/105 [==============================] - 0s 211us/sample - loss: 0.7565 - val_loss: 0.8971\n",
      "Epoch 284/500\n",
      "105/105 [==============================] - 0s 213us/sample - loss: 0.7572 - val_loss: 0.8949\n",
      "Epoch 285/500\n",
      "105/105 [==============================] - 0s 210us/sample - loss: 0.7571 - val_loss: 0.8939\n",
      "Epoch 286/500\n",
      "105/105 [==============================] - 0s 212us/sample - loss: 0.7571 - val_loss: 0.8938\n",
      "Epoch 287/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7567 - val_loss: 0.8943\n",
      "Epoch 288/500\n",
      "105/105 [==============================] - 0s 173us/sample - loss: 0.7577 - val_loss: 0.8940\n",
      "Epoch 289/500\n",
      "105/105 [==============================] - 0s 222us/sample - loss: 0.7567 - val_loss: 0.8940\n",
      "Epoch 290/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7570 - val_loss: 0.8901\n",
      "Epoch 291/500\n",
      "105/105 [==============================] - 0s 206us/sample - loss: 0.7575 - val_loss: 0.8913\n",
      "Epoch 292/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7576 - val_loss: 0.8957\n",
      "Epoch 293/500\n",
      "105/105 [==============================] - 0s 241us/sample - loss: 0.7565 - val_loss: 0.8964\n",
      "Epoch 294/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7562 - val_loss: 0.9010\n",
      "Epoch 295/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7558 - val_loss: 0.9026\n",
      "Epoch 296/500\n",
      "105/105 [==============================] - 0s 213us/sample - loss: 0.7573 - val_loss: 0.9059\n",
      "Epoch 297/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7561 - val_loss: 0.9060\n",
      "Epoch 298/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7563 - val_loss: 0.9106\n",
      "Epoch 299/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7578 - val_loss: 0.9174\n",
      "Epoch 300/500\n",
      "105/105 [==============================] - 0s 172us/sample - loss: 0.7572 - val_loss: 0.9192\n",
      "Epoch 301/500\n",
      "105/105 [==============================] - 0s 214us/sample - loss: 0.7587 - val_loss: 0.9171\n",
      "Epoch 302/500\n",
      "105/105 [==============================] - 0s 201us/sample - loss: 0.7566 - val_loss: 0.9145\n",
      "Epoch 303/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7564 - val_loss: 0.9101\n",
      "Epoch 304/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7564 - val_loss: 0.9091\n",
      "Epoch 305/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7569 - val_loss: 0.9143\n",
      "Epoch 306/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7560 - val_loss: 0.9129\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7560 - val_loss: 0.9131\n",
      "Epoch 308/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7571 - val_loss: 0.9180\n",
      "Epoch 309/500\n",
      "105/105 [==============================] - 0s 164us/sample - loss: 0.7569 - val_loss: 0.9174\n",
      "Epoch 310/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7577 - val_loss: 0.9214\n",
      "Epoch 311/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7585 - val_loss: 0.9162\n",
      "Epoch 312/500\n",
      "105/105 [==============================] - 0s 201us/sample - loss: 0.7564 - val_loss: 0.9113\n",
      "Epoch 313/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7573 - val_loss: 0.9101\n",
      "Epoch 314/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7567 - val_loss: 0.9077\n",
      "Epoch 315/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7563 - val_loss: 0.9057\n",
      "Epoch 316/500\n",
      "105/105 [==============================] - 0s 165us/sample - loss: 0.7562 - val_loss: 0.9022\n",
      "Epoch 317/500\n",
      "105/105 [==============================] - 0s 175us/sample - loss: 0.7561 - val_loss: 0.9039\n",
      "Epoch 318/500\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 0.7558 - val_loss: 0.9065\n",
      "Epoch 319/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7574 - val_loss: 0.9076\n",
      "Epoch 320/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7557 - val_loss: 0.9098\n",
      "Epoch 321/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7560 - val_loss: 0.9088\n",
      "Epoch 322/500\n",
      "105/105 [==============================] - 0s 168us/sample - loss: 0.7566 - val_loss: 0.9071\n",
      "Epoch 323/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7559 - val_loss: 0.9072\n",
      "Epoch 324/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7561 - val_loss: 0.9060\n",
      "Epoch 325/500\n",
      "105/105 [==============================] - 0s 205us/sample - loss: 0.7560 - val_loss: 0.9034\n",
      "Epoch 326/500\n",
      "105/105 [==============================] - 0s 167us/sample - loss: 0.7566 - val_loss: 0.9051\n",
      "Epoch 327/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7558 - val_loss: 0.9063\n",
      "Epoch 328/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7557 - val_loss: 0.9106\n",
      "Epoch 329/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7562 - val_loss: 0.9104\n",
      "Epoch 330/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7557 - val_loss: 0.9101\n",
      "Epoch 331/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7558 - val_loss: 0.9087\n",
      "Epoch 332/500\n",
      "105/105 [==============================] - 0s 214us/sample - loss: 0.7557 - val_loss: 0.9070\n",
      "Epoch 333/500\n",
      "105/105 [==============================] - 0s 240us/sample - loss: 0.7566 - val_loss: 0.9076\n",
      "Epoch 334/500\n",
      "105/105 [==============================] - 0s 317us/sample - loss: 0.7572 - val_loss: 0.9052\n",
      "Epoch 335/500\n",
      "105/105 [==============================] - 0s 314us/sample - loss: 0.7571 - val_loss: 0.9061\n",
      "Epoch 336/500\n",
      "105/105 [==============================] - 0s 306us/sample - loss: 0.7574 - val_loss: 0.9049\n",
      "Epoch 337/500\n",
      "105/105 [==============================] - 0s 315us/sample - loss: 0.7560 - val_loss: 0.9054\n",
      "Epoch 338/500\n",
      "105/105 [==============================] - 0s 227us/sample - loss: 0.7568 - val_loss: 0.9061\n",
      "Epoch 339/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7561 - val_loss: 0.9040\n",
      "Epoch 340/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7557 - val_loss: 0.9035\n",
      "Epoch 341/500\n",
      "105/105 [==============================] - 0s 182us/sample - loss: 0.7572 - val_loss: 0.9025\n",
      "Epoch 342/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7571 - val_loss: 0.9052\n",
      "Epoch 343/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7561 - val_loss: 0.9067\n",
      "Epoch 344/500\n",
      "105/105 [==============================] - 0s 218us/sample - loss: 0.7565 - val_loss: 0.9101\n",
      "Epoch 345/500\n",
      "105/105 [==============================] - 0s 181us/sample - loss: 0.7577 - val_loss: 0.9070\n",
      "Epoch 346/500\n",
      "105/105 [==============================] - 0s 176us/sample - loss: 0.7590 - val_loss: 0.9080\n",
      "Epoch 347/500\n",
      "105/105 [==============================] - 0s 180us/sample - loss: 0.7555 - val_loss: 0.9080\n",
      "Epoch 348/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7568 - val_loss: 0.9056\n",
      "Epoch 349/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7564 - val_loss: 0.9058\n",
      "Epoch 350/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7559 - val_loss: 0.9077\n",
      "Epoch 351/500\n",
      "105/105 [==============================] - 0s 179us/sample - loss: 0.7562 - val_loss: 0.9076\n",
      "Epoch 352/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7564 - val_loss: 0.9042\n",
      "Epoch 353/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7570 - val_loss: 0.9037\n",
      "Epoch 354/500\n",
      "105/105 [==============================] - 0s 215us/sample - loss: 0.7575 - val_loss: 0.9148\n",
      "Epoch 355/500\n",
      "105/105 [==============================] - 0s 225us/sample - loss: 0.7574 - val_loss: 0.9132\n",
      "Epoch 356/500\n",
      "105/105 [==============================] - 0s 225us/sample - loss: 0.7581 - val_loss: 0.9185\n",
      "Epoch 357/500\n",
      "105/105 [==============================] - 0s 274us/sample - loss: 0.7583 - val_loss: 0.9157\n",
      "Epoch 358/500\n",
      "105/105 [==============================] - 0s 214us/sample - loss: 0.7575 - val_loss: 0.9192\n",
      "Epoch 359/500\n",
      "105/105 [==============================] - 0s 240us/sample - loss: 0.7572 - val_loss: 0.9175\n",
      "Epoch 360/500\n",
      "105/105 [==============================] - 0s 222us/sample - loss: 0.7569 - val_loss: 0.9187\n",
      "Epoch 361/500\n",
      "105/105 [==============================] - 0s 239us/sample - loss: 0.7574 - val_loss: 0.9204\n",
      "Epoch 362/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7577 - val_loss: 0.9202\n",
      "Epoch 363/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7578 - val_loss: 0.9156\n",
      "Epoch 364/500\n",
      "105/105 [==============================] - 0s 217us/sample - loss: 0.7567 - val_loss: 0.9150\n",
      "Epoch 365/500\n",
      "105/105 [==============================] - 0s 212us/sample - loss: 0.7577 - val_loss: 0.9146\n",
      "Epoch 366/500\n",
      "105/105 [==============================] - 0s 188us/sample - loss: 0.7566 - val_loss: 0.9167\n",
      "Epoch 367/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7589 - val_loss: 0.9139\n",
      "Epoch 368/500\n",
      "105/105 [==============================] - 0s 203us/sample - loss: 0.7571 - val_loss: 0.9178\n",
      "Epoch 369/500\n",
      "105/105 [==============================] - 0s 219us/sample - loss: 0.7572 - val_loss: 0.9157\n",
      "Epoch 370/500\n",
      "105/105 [==============================] - 0s 216us/sample - loss: 0.7580 - val_loss: 0.9101\n",
      "Epoch 371/500\n",
      "105/105 [==============================] - 0s 231us/sample - loss: 0.7572 - val_loss: 0.9108\n",
      "Epoch 372/500\n",
      "105/105 [==============================] - 0s 214us/sample - loss: 0.7570 - val_loss: 0.9090\n",
      "Epoch 373/500\n",
      "105/105 [==============================] - 0s 213us/sample - loss: 0.7575 - val_loss: 0.9075\n",
      "Epoch 374/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7576 - val_loss: 0.9093\n",
      "Epoch 375/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7570 - val_loss: 0.9101\n",
      "Epoch 376/500\n",
      "105/105 [==============================] - 0s 220us/sample - loss: 0.7561 - val_loss: 0.9092\n",
      "Epoch 377/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7579 - val_loss: 0.9067\n",
      "Epoch 378/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7563 - val_loss: 0.9042\n",
      "Epoch 379/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7563 - val_loss: 0.9018\n",
      "Epoch 380/500\n",
      "105/105 [==============================] - 0s 206us/sample - loss: 0.7567 - val_loss: 0.8977\n",
      "Epoch 381/500\n",
      "105/105 [==============================] - 0s 220us/sample - loss: 0.7569 - val_loss: 0.8975\n",
      "Epoch 382/500\n",
      "105/105 [==============================] - 0s 206us/sample - loss: 0.7561 - val_loss: 0.8986\n",
      "Epoch 383/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 211us/sample - loss: 0.7564 - val_loss: 0.8962\n",
      "Epoch 384/500\n",
      "105/105 [==============================] - 0s 210us/sample - loss: 0.7563 - val_loss: 0.8954\n",
      "Epoch 385/500\n",
      "105/105 [==============================] - 0s 205us/sample - loss: 0.7576 - val_loss: 0.8948\n",
      "Epoch 386/500\n",
      "105/105 [==============================] - 0s 207us/sample - loss: 0.7567 - val_loss: 0.8964\n",
      "Epoch 387/500\n",
      "105/105 [==============================] - 0s 210us/sample - loss: 0.7567 - val_loss: 0.8966\n",
      "Epoch 388/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7572 - val_loss: 0.8946\n",
      "Epoch 389/500\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 0.7571 - val_loss: 0.8984\n",
      "Epoch 390/500\n",
      "105/105 [==============================] - 0s 214us/sample - loss: 0.7561 - val_loss: 0.9010\n",
      "Epoch 391/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7565 - val_loss: 0.9045\n",
      "Epoch 392/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7560 - val_loss: 0.9062\n",
      "Epoch 393/500\n",
      "105/105 [==============================] - 0s 178us/sample - loss: 0.7569 - val_loss: 0.9069\n",
      "Epoch 394/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7573 - val_loss: 0.9066\n",
      "Epoch 395/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7559 - val_loss: 0.9072\n",
      "Epoch 396/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7564 - val_loss: 0.9008\n",
      "Epoch 397/500\n",
      "105/105 [==============================] - 0s 211us/sample - loss: 0.7559 - val_loss: 0.9002\n",
      "Epoch 398/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7558 - val_loss: 0.9007\n",
      "Epoch 399/500\n",
      "105/105 [==============================] - 0s 225us/sample - loss: 0.7564 - val_loss: 0.9002\n",
      "Epoch 400/500\n",
      "105/105 [==============================] - 0s 232us/sample - loss: 0.7561 - val_loss: 0.9008\n",
      "Epoch 401/500\n",
      "105/105 [==============================] - 0s 189us/sample - loss: 0.7581 - val_loss: 0.9011\n",
      "Epoch 402/500\n",
      "105/105 [==============================] - 0s 212us/sample - loss: 0.7577 - val_loss: 0.9011\n",
      "Epoch 403/500\n",
      "105/105 [==============================] - 0s 221us/sample - loss: 0.7571 - val_loss: 0.9008\n",
      "Epoch 404/500\n",
      "105/105 [==============================] - 0s 215us/sample - loss: 0.7592 - val_loss: 0.9024\n",
      "Epoch 405/500\n",
      "105/105 [==============================] - 0s 217us/sample - loss: 0.7571 - val_loss: 0.9037\n",
      "Epoch 406/500\n",
      "105/105 [==============================] - 0s 208us/sample - loss: 0.7558 - val_loss: 0.9041\n",
      "Epoch 407/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7563 - val_loss: 0.9016\n",
      "Epoch 408/500\n",
      "105/105 [==============================] - 0s 186us/sample - loss: 0.7560 - val_loss: 0.9046\n",
      "Epoch 409/500\n",
      "105/105 [==============================] - 0s 212us/sample - loss: 0.7581 - val_loss: 0.9046\n",
      "Epoch 410/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7564 - val_loss: 0.9041\n",
      "Epoch 411/500\n",
      "105/105 [==============================] - 0s 201us/sample - loss: 0.7565 - val_loss: 0.9085\n",
      "Epoch 412/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7562 - val_loss: 0.9103\n",
      "Epoch 413/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7561 - val_loss: 0.9083\n",
      "Epoch 414/500\n",
      "105/105 [==============================] - 0s 239us/sample - loss: 0.7564 - val_loss: 0.9107\n",
      "Epoch 415/500\n",
      "105/105 [==============================] - 0s 212us/sample - loss: 0.7561 - val_loss: 0.9128\n",
      "Epoch 416/500\n",
      "105/105 [==============================] - 0s 230us/sample - loss: 0.7573 - val_loss: 0.9091\n",
      "Epoch 417/500\n",
      "105/105 [==============================] - 0s 192us/sample - loss: 0.7562 - val_loss: 0.9113\n",
      "Epoch 418/500\n",
      "105/105 [==============================] - 0s 224us/sample - loss: 0.7572 - val_loss: 0.9139\n",
      "Epoch 419/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7591 - val_loss: 0.9119\n",
      "Epoch 420/500\n",
      "105/105 [==============================] - 0s 201us/sample - loss: 0.7564 - val_loss: 0.9115\n",
      "Epoch 421/500\n",
      "105/105 [==============================] - 0s 245us/sample - loss: 0.7566 - val_loss: 0.9080\n",
      "Epoch 422/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7561 - val_loss: 0.9108\n",
      "Epoch 423/500\n",
      "105/105 [==============================] - 0s 216us/sample - loss: 0.7560 - val_loss: 0.9133\n",
      "Epoch 424/500\n",
      "105/105 [==============================] - 0s 194us/sample - loss: 0.7572 - val_loss: 0.9107\n",
      "Epoch 425/500\n",
      "105/105 [==============================] - 0s 256us/sample - loss: 0.7568 - val_loss: 0.9111\n",
      "Epoch 426/500\n",
      "105/105 [==============================] - 0s 195us/sample - loss: 0.7561 - val_loss: 0.9102\n",
      "Epoch 427/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7571 - val_loss: 0.9080\n",
      "Epoch 428/500\n",
      "105/105 [==============================] - 0s 210us/sample - loss: 0.7572 - val_loss: 0.9053\n",
      "Epoch 429/500\n",
      "105/105 [==============================] - 0s 209us/sample - loss: 0.7561 - val_loss: 0.9051\n",
      "Epoch 430/500\n",
      "105/105 [==============================] - 0s 223us/sample - loss: 0.7566 - val_loss: 0.9089\n",
      "Epoch 431/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7565 - val_loss: 0.9066\n",
      "Epoch 432/500\n",
      "105/105 [==============================] - 0s 199us/sample - loss: 0.7565 - val_loss: 0.9084\n",
      "Epoch 433/500\n",
      "105/105 [==============================] - 0s 218us/sample - loss: 0.7572 - val_loss: 0.9066\n",
      "Epoch 434/500\n",
      "105/105 [==============================] - 0s 209us/sample - loss: 0.7577 - val_loss: 0.9079\n",
      "Epoch 435/500\n",
      "105/105 [==============================] - 0s 207us/sample - loss: 0.7566 - val_loss: 0.9062\n",
      "Epoch 436/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7563 - val_loss: 0.9034\n",
      "Epoch 437/500\n",
      "105/105 [==============================] - 0s 214us/sample - loss: 0.7562 - val_loss: 0.9070\n",
      "Epoch 438/500\n",
      "105/105 [==============================] - 0s 208us/sample - loss: 0.7564 - val_loss: 0.9062\n",
      "Epoch 439/500\n",
      "105/105 [==============================] - 0s 197us/sample - loss: 0.7564 - val_loss: 0.9038\n",
      "Epoch 440/500\n",
      "105/105 [==============================] - 0s 218us/sample - loss: 0.7564 - val_loss: 0.9075\n",
      "Epoch 441/500\n",
      "105/105 [==============================] - 0s 217us/sample - loss: 0.7567 - val_loss: 0.9098\n",
      "Epoch 442/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7560 - val_loss: 0.9110\n",
      "Epoch 443/500\n",
      "105/105 [==============================] - 0s 199us/sample - loss: 0.7568 - val_loss: 0.9095\n",
      "Epoch 444/500\n",
      "105/105 [==============================] - 0s 213us/sample - loss: 0.7563 - val_loss: 0.9102\n",
      "Epoch 445/500\n",
      "105/105 [==============================] - 0s 199us/sample - loss: 0.7570 - val_loss: 0.9103\n",
      "Epoch 446/500\n",
      "105/105 [==============================] - 0s 202us/sample - loss: 0.7559 - val_loss: 0.9059\n",
      "Epoch 447/500\n",
      "105/105 [==============================] - 0s 232us/sample - loss: 0.7556 - val_loss: 0.9042\n",
      "Epoch 448/500\n",
      "105/105 [==============================] - 0s 211us/sample - loss: 0.7569 - val_loss: 0.9024\n",
      "Epoch 449/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7558 - val_loss: 0.9019\n",
      "Epoch 450/500\n",
      "105/105 [==============================] - 0s 204us/sample - loss: 0.7561 - val_loss: 0.9003\n",
      "Epoch 451/500\n",
      "105/105 [==============================] - 0s 221us/sample - loss: 0.7564 - val_loss: 0.8994\n",
      "Epoch 452/500\n",
      "105/105 [==============================] - 0s 210us/sample - loss: 0.7567 - val_loss: 0.8963\n",
      "Epoch 453/500\n",
      "105/105 [==============================] - 0s 207us/sample - loss: 0.7575 - val_loss: 0.8984\n",
      "Epoch 454/500\n",
      "105/105 [==============================] - 0s 203us/sample - loss: 0.7563 - val_loss: 0.9004\n",
      "Epoch 455/500\n",
      "105/105 [==============================] - 0s 212us/sample - loss: 0.7564 - val_loss: 0.8964\n",
      "Epoch 456/500\n",
      "105/105 [==============================] - 0s 222us/sample - loss: 0.7565 - val_loss: 0.8982\n",
      "Epoch 457/500\n",
      "105/105 [==============================] - 0s 207us/sample - loss: 0.7565 - val_loss: 0.8998\n",
      "Epoch 458/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7566 - val_loss: 0.9025\n",
      "Epoch 459/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 216us/sample - loss: 0.7593 - val_loss: 0.8994\n",
      "Epoch 460/500\n",
      "105/105 [==============================] - 0s 213us/sample - loss: 0.7564 - val_loss: 0.8985\n",
      "Epoch 461/500\n",
      "105/105 [==============================] - 0s 185us/sample - loss: 0.7562 - val_loss: 0.9006\n",
      "Epoch 462/500\n",
      "105/105 [==============================] - 0s 198us/sample - loss: 0.7571 - val_loss: 0.9001\n",
      "Epoch 463/500\n",
      "105/105 [==============================] - 0s 203us/sample - loss: 0.7565 - val_loss: 0.9003\n",
      "Epoch 464/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7568 - val_loss: 0.8995\n",
      "Epoch 465/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7569 - val_loss: 0.8950\n",
      "Epoch 466/500\n",
      "105/105 [==============================] - 0s 193us/sample - loss: 0.7567 - val_loss: 0.8986\n",
      "Epoch 467/500\n",
      "105/105 [==============================] - 0s 187us/sample - loss: 0.7565 - val_loss: 0.8991\n",
      "Epoch 468/500\n",
      "105/105 [==============================] - 0s 226us/sample - loss: 0.7561 - val_loss: 0.9019\n",
      "Epoch 469/500\n",
      "105/105 [==============================] - 0s 216us/sample - loss: 0.7559 - val_loss: 0.9035\n",
      "Epoch 470/500\n",
      "105/105 [==============================] - 0s 249us/sample - loss: 0.7569 - val_loss: 0.9054\n",
      "Epoch 471/500\n",
      "105/105 [==============================] - 0s 200us/sample - loss: 0.7568 - val_loss: 0.9105\n",
      "Epoch 472/500\n",
      "105/105 [==============================] - 0s 196us/sample - loss: 0.7561 - val_loss: 0.9097\n",
      "Epoch 473/500\n",
      "105/105 [==============================] - 0s 225us/sample - loss: 0.7556 - val_loss: 0.9085\n",
      "Epoch 474/500\n",
      "105/105 [==============================] - 0s 266us/sample - loss: 0.7576 - val_loss: 0.9035\n",
      "Epoch 475/500\n",
      "105/105 [==============================] - 0s 287us/sample - loss: 0.7567 - val_loss: 0.9040\n",
      "Epoch 476/500\n",
      "105/105 [==============================] - 0s 225us/sample - loss: 0.7574 - val_loss: 0.9039\n",
      "Epoch 477/500\n",
      "105/105 [==============================] - 0s 266us/sample - loss: 0.7557 - val_loss: 0.9042\n",
      "Epoch 478/500\n",
      "105/105 [==============================] - 0s 244us/sample - loss: 0.7577 - val_loss: 0.9015\n",
      "Epoch 479/500\n",
      "105/105 [==============================] - 0s 238us/sample - loss: 0.7573 - val_loss: 0.8982\n",
      "Epoch 480/500\n",
      "105/105 [==============================] - 0s 276us/sample - loss: 0.7565 - val_loss: 0.8948\n",
      "Epoch 481/500\n",
      "105/105 [==============================] - 0s 248us/sample - loss: 0.7581 - val_loss: 0.8938\n",
      "Epoch 482/500\n",
      "105/105 [==============================] - 0s 313us/sample - loss: 0.7573 - val_loss: 0.8979\n",
      "Epoch 483/500\n",
      "105/105 [==============================] - 0s 327us/sample - loss: 0.7560 - val_loss: 0.8999\n",
      "Epoch 484/500\n",
      "105/105 [==============================] - 0s 272us/sample - loss: 0.7564 - val_loss: 0.8963\n",
      "Epoch 485/500\n",
      "105/105 [==============================] - 0s 228us/sample - loss: 0.7575 - val_loss: 0.8988\n",
      "Epoch 486/500\n",
      "105/105 [==============================] - 0s 268us/sample - loss: 0.7568 - val_loss: 0.8993\n",
      "Epoch 487/500\n",
      "105/105 [==============================] - 0s 236us/sample - loss: 0.7572 - val_loss: 0.8984\n",
      "Epoch 488/500\n",
      "105/105 [==============================] - 0s 222us/sample - loss: 0.7559 - val_loss: 0.8976\n",
      "Epoch 489/500\n",
      "105/105 [==============================] - 0s 233us/sample - loss: 0.7579 - val_loss: 0.8972\n",
      "Epoch 490/500\n",
      "105/105 [==============================] - 0s 282us/sample - loss: 0.7575 - val_loss: 0.8963\n",
      "Epoch 491/500\n",
      "105/105 [==============================] - 0s 283us/sample - loss: 0.7563 - val_loss: 0.8983\n",
      "Epoch 492/500\n",
      "105/105 [==============================] - 0s 236us/sample - loss: 0.7561 - val_loss: 0.8996\n",
      "Epoch 493/500\n",
      "105/105 [==============================] - 0s 243us/sample - loss: 0.7581 - val_loss: 0.8986\n",
      "Epoch 494/500\n",
      "105/105 [==============================] - 0s 231us/sample - loss: 0.7561 - val_loss: 0.8956\n",
      "Epoch 495/500\n",
      "105/105 [==============================] - 0s 217us/sample - loss: 0.7566 - val_loss: 0.8996\n",
      "Epoch 496/500\n",
      "105/105 [==============================] - 0s 232us/sample - loss: 0.7569 - val_loss: 0.9047\n",
      "Epoch 497/500\n",
      "105/105 [==============================] - 0s 214us/sample - loss: 0.7559 - val_loss: 0.9045\n",
      "Epoch 498/500\n",
      "105/105 [==============================] - 0s 224us/sample - loss: 0.7556 - val_loss: 0.9034\n",
      "Epoch 499/500\n",
      "105/105 [==============================] - 0s 210us/sample - loss: 0.7567 - val_loss: 0.9009\n",
      "Epoch 500/500\n",
      "105/105 [==============================] - 0s 245us/sample - loss: 0.7583 - val_loss: 0.9009\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs[:300], history.history['loss'][:300],label='Training loss')\n",
    "plt.plot(epochs[:300], history.history['val_loss'][:300], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simple_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "model.load_weights('simple_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/sample - loss: 0.9472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9471773433685303"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
